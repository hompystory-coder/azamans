# âš¡ ë¹ ë¥¸ ì‹œì‘ ê°€ì´ë“œ - ë¡œì»¬ PC AI ì‡¼ì¸  ìƒì„±

**5ë¶„ ì•ˆì— ì‹œì‘í•˜ê¸°!**

---

## ğŸš€ ì´ˆê°„ë‹¨ ì„¤ì¹˜ (ë³µì‚¬ & ë¶™ì—¬ë„£ê¸°)

### **1ë‹¨ê³„: ê¸°ë³¸ ì„¤ì • (1ë¶„)**

```bash
# í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ë¡œ ì´ë™
cd /home/azamans/webapp/local-shorts-system

# ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”
python -m venv venv
source venv/bin/activate  # Linux/macOS
# venv\Scripts\activate   # Windows
```

---

### **2ë‹¨ê³„: PyTorch ì„¤ì¹˜ (1ë¶„)**

```bash
# NVIDIA GPU ìˆëŠ” ê²½ìš° (ê¶Œì¥)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# GPU ì—†ëŠ” ê²½ìš°
pip install torch torchvision torchaudio
```

---

### **3ë‹¨ê³„: ì˜ì¡´ì„± ì„¤ì¹˜ (1ë¶„)**

```bash
pip install -r requirements.txt
```

---

### **4ë‹¨ê³„: AI ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (20-30ë¶„, ìµœì´ˆ 1íšŒë§Œ)**

```bash
# ìë™ ë‹¤ìš´ë¡œë“œ (15.3 GB)
python scripts/install_models.py
```

---

### **5ë‹¨ê³„: Ollama ì„¤ì¹˜ (2ë¶„)**

```bash
# Ollama ì„¤ì¹˜
curl -fsSL https://ollama.ai/install.sh | sh  # Linux/macOS
# Windows: https://ollama.ai/download

# LLaMA ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (4.7 GB)
ollama pull llama3.1:8b

# Ollama ì„œë²„ ì‹œì‘ (ë³„ë„ í„°ë¯¸ë„)
ollama serve
```

---

## ğŸ¬ ì‹¤í–‰ ë° ì‚¬ìš©

### **ì„œë²„ ì‹œì‘**

```bash
# ë°±ì—”ë“œ ì„œë²„ ì‹¤í–‰
cd backend
python app.py

# ë¸Œë¼ìš°ì € ì—´ê¸°
# http://localhost:8000
```

---

### **ì‡¼ì¸  ìƒì„± (3ê°€ì§€ ë°©ë²•)**

#### **ë°©ë²• 1: cURL**

```bash
# ì‡¼ì¸  ìƒì„±
curl -X POST http://localhost:8000/api/shorts/generate \
  -H "Content-Type: application/json" \
  -d '{
    "url": "https://shopping.naver.com/your-product-url",
    "character_id": "executive-fox",
    "duration": 15
  }'

# ì‘ë‹µì—ì„œ job_id í™•ì¸
# {"job_id": "shorts_xxx_yyy", "status": "pending"}

# ìƒíƒœ í™•ì¸ (5-10ë¶„ ëŒ€ê¸°)
curl http://localhost:8000/api/shorts/status/shorts_xxx_yyy

# ë‹¤ìš´ë¡œë“œ
curl -O http://localhost:8000/api/shorts/download/shorts_xxx_yyy
```

---

#### **ë°©ë²• 2: Python ìŠ¤í¬ë¦½íŠ¸**

```python
# quick_generate.py
import requests
import time

API = "http://localhost:8000"

# ì‡¼ì¸  ìƒì„±
resp = requests.post(f"{API}/api/shorts/generate", json={
    "url": "https://example.com/product",
    "character_id": "executive-fox"
})
job_id = resp.json()["job_id"]
print(f"Job ID: {job_id}")

# ìƒíƒœ í™•ì¸ (í´ë§)
while True:
    resp = requests.get(f"{API}/api/shorts/status/{job_id}")
    status = resp.json()
    print(f"{status['progress']}% - {status['message']}")
    if status["status"] == "completed":
        break
    time.sleep(10)

# ë‹¤ìš´ë¡œë“œ
resp = requests.get(f"{API}/api/shorts/download/{job_id}")
with open(f"{job_id}.mp4", "wb") as f:
    f.write(resp.content)
print("âœ… ì™„ë£Œ!")
```

```bash
python quick_generate.py
```

---

#### **ë°©ë²• 3: Swagger UI (ê°€ì¥ ì‰¬ì›€)**

1. ë¸Œë¼ìš°ì €: http://localhost:8000/docs
2. `POST /api/shorts/generate` í´ë¦­
3. `Try it out` â†’ ì •ë³´ ì…ë ¥ â†’ `Execute`
4. `job_id` ë³µì‚¬
5. `GET /api/shorts/status/{job_id}` ë¡œ ìƒíƒœ í™•ì¸
6. ì™„ë£Œë˜ë©´ `GET /api/shorts/download/{job_id}` ë¡œ ë‹¤ìš´ë¡œë“œ

---

## ğŸ“Š ì‹œê°„ ë° ì„±ëŠ¥

```
RTX 3060 ê¸°ì¤€: 7.5ë¶„ / ì‡¼ì¸ 
GTX 1660:      10-12ë¶„ / ì‡¼ì¸ 
CPU Only:      30-45ë¶„ / ì‡¼ì¸ 
```

---

## ğŸ¯ ìºë¦­í„° ëª©ë¡

```bash
# ìºë¦­í„° ëª©ë¡ ì¡°íšŒ
curl http://localhost:8000/api/characters | jq

# ì£¼ìš” ìºë¦­í„°:
# - executive-fox (ğŸ¦Š ì´ê·¸ì œíí‹°ë¸Œ í­ìŠ¤) - ë¹„ì¦ˆë‹ˆìŠ¤
# - tech-fox (ğŸ¦Š í…Œí¬ í­ìŠ¤) - ê¸°ìˆ 
# - fashionista-cat (ğŸ˜º íŒ¨ì…”ë‹ˆìŠ¤íƒ€ ìº£) - íŒ¨ì…˜
# - chef-penguin (ğŸ§ ì…°í”„ í­ê·„) - ìŒì‹
# - comedian-parrot (ğŸ¦œ ì½”ë¯¸ë””ì–¸ íŒ¨ëŸ¿) - ì—”í„°í…Œì¸ë¨¼íŠ¸
```

---

## â— ë¬¸ì œ í•´ê²°

### **CUDA Out of Memory**
```bash
# nvidia-smi ë¡œ ë‹¤ë¥¸ í”„ë¡œê·¸ë¨ í™•ì¸ ë° ì¢…ë£Œ
nvidia-smi
```

### **Ollama ì—°ê²° ì‹¤íŒ¨**
```bash
# Ollama ì„œë²„ ì¬ì‹œì‘
ollama serve
```

### **ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨**
```bash
# ìºì‹œ ì‚­ì œ í›„ ì¬ì‹œë„
rm -rf ~/.cache/huggingface
python scripts/install_models.py
```

---

## ğŸ“š ìì„¸í•œ ê°€ì´ë“œ

- **ì „ì²´ ê°€ì´ë“œ**: `DEPLOYMENT_GUIDE.md`
- **API ë¬¸ì„œ**: http://localhost:8000/docs
- **ì‹œìŠ¤í…œ ì„¤ê³„**: `LOCAL_PC_SHORTS_SYSTEM.md`

---

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

```
â–¡ Python 3.8-3.11 ì„¤ì¹˜ë¨
â–¡ NVIDIA GPU ë“œë¼ì´ë²„ ìµœì‹  (ì„ íƒ)
â–¡ ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”
â–¡ PyTorch ì„¤ì¹˜ (CUDA ë²„ì „)
â–¡ requirements.txt ì„¤ì¹˜
â–¡ AI ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (15.3 GB)
â–¡ Ollama ì„¤ì¹˜ ë° llama3.1:8b ë‹¤ìš´ë¡œë“œ
â–¡ Ollama ì„œë²„ ì‹¤í–‰ ì¤‘
â–¡ ë°±ì—”ë“œ ì„œë²„ ì‹¤í–‰ ì¤‘
â–¡ http://localhost:8000 ì ‘ì† ê°€ëŠ¥
```

---

## ğŸ‰ ì™„ë£Œ!

**ì´ì œ ë¡œì»¬ PCì—ì„œ AI ì‡¼ì¸ ë¥¼ ë¬´ì œí•œìœ¼ë¡œ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!**

```
âœ… API ë¹„ìš©: $0
âœ… ë¬´ì œí•œ ìƒì„±
âœ… ì™„ì „í•œ í”„ë¼ì´ë²„ì‹œ
âœ… ì˜¤í”„ë¼ì¸ ì‘ë™
```

**ğŸš€ ì¦ê±°ìš´ ì‡¼ì¸  ì œì‘ ë˜ì„¸ìš”! ğŸš€**
