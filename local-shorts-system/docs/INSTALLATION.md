# ğŸ“¦ ì„¤ì¹˜ ê°€ì´ë“œ

## ğŸ¯ ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

### ìµœì†Œ ì‚¬ì–‘
- **OS**: Windows 10/11, macOS 12+, Ubuntu 20.04+
- **CPU**: Intel i5 8ì„¸ëŒ€ ì´ìƒ / AMD Ryzen 5
- **RAM**: 16GB
- **GPU**: NVIDIA GTX 1660 (6GB VRAM) ì´ìƒ
- **ì €ì¥ì†Œ**: 50GB SSD ì—¬ìœ  ê³µê°„
- **ì¸í„°ë„·**: ëª¨ë¸ ë‹¤ìš´ë¡œë“œìš© (ìµœì´ˆ 1íšŒ)

### ê¶Œì¥ ì‚¬ì–‘
- **CPU**: Intel i7 10ì„¸ëŒ€ ì´ìƒ / AMD Ryzen 7
- **RAM**: 32GB
- **GPU**: NVIDIA RTX 3060 (12GB VRAM) ì´ìƒ
- **ì €ì¥ì†Œ**: 100GB NVMe SSD

### ìµœì  ì‚¬ì–‘
- **CPU**: Intel i9 12ì„¸ëŒ€ ì´ìƒ / AMD Ryzen 9
- **RAM**: 64GB
- **GPU**: NVIDIA RTX 4070 Ti (16GB VRAM) ì´ìƒ
- **ì €ì¥ì†Œ**: 200GB NVMe SSD

---

## ğŸš€ ë¹ ë¥¸ ì„¤ì¹˜ (5ë¶„)

### 1. Python ì„¤ì¹˜ (3.8 ì´ìƒ)

#### Windows
```bash
# Python 3.10 ë‹¤ìš´ë¡œë“œ
https://www.python.org/downloads/

# ì„¤ì¹˜ ì‹œ "Add Python to PATH" ì²´í¬ í•„ìˆ˜!
```

#### macOS
```bash
brew install python@3.10
```

#### Linux (Ubuntu/Debian)
```bash
sudo apt update
sudo apt install python3.10 python3.10-venv python3-pip
```

---

### 2. í”„ë¡œì íŠ¸ í´ë¡ 

```bash
# Git í´ë¡ 
git clone <repository-url>
cd local-shorts-system

# ë˜ëŠ” ZIP ë‹¤ìš´ë¡œë“œ í›„ ì••ì¶• í•´ì œ
```

---

### 3. ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”

#### Windows
```bash
python -m venv venv
venv\Scripts\activate
```

#### macOS / Linux
```bash
python3 -m venv venv
source venv/bin/activate
```

í™œì„±í™”ë˜ë©´ í”„ë¡¬í”„íŠ¸ ì•ì— `(venv)`ê°€ í‘œì‹œë©ë‹ˆë‹¤.

---

### 4. PyTorch ì„¤ì¹˜ (GPU ì§€ì›)

#### NVIDIA GPU ìˆëŠ” ê²½ìš° (ê¶Œì¥)

**CUDA 11.8** (ëŒ€ë¶€ë¶„ì˜ ìµœì‹  GPU ì§€ì›):
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

**CUDA 12.1** (RTX 40 ì‹œë¦¬ì¦ˆ ë“±):
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

#### CPUë§Œ ìˆëŠ” ê²½ìš°
```bash
pip install torch torchvision torchaudio
```

**ì„¤ì¹˜ í™•ì¸:**
```bash
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA available: {torch.cuda.is_available()}')"
```

---

### 5. ì˜ì¡´ì„± ì„¤ì¹˜

```bash
pip install -r requirements.txt
```

ì´ ê³¼ì •ì€ 5-10ë¶„ ì†Œìš”ë©ë‹ˆë‹¤.

---

### 6. AI ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ìµœì´ˆ 1íšŒ)

```bash
python scripts/install_models.py
```

**ë‹¤ìš´ë¡œë“œë˜ëŠ” ëª¨ë¸:**
- âœ… Stable Diffusion XL (6.9 GB) - ì´ë¯¸ì§€ ìƒì„±
- âœ… Coqui TTS XTTS-v2 (2 GB) - ìŒì„± í•©ì„±
- âš ï¸ Ollama LLaMA 3.1 (4.7 GB) - LLM (ì„ íƒ)

**ì˜ˆìƒ ì†Œìš” ì‹œê°„:**
- ë¹ ë¥¸ ì¸í„°ë„·: 20-30ë¶„
- ë³´í†µ ì¸í„°ë„·: 30-60ë¶„

**ë””ìŠ¤í¬ ê³µê°„:** ì´ ~15GB í•„ìš”

---

### 7. Ollama ì„¤ì¹˜ (ì„ íƒ, LLMìš©)

AI ìŠ¤í¬ë¦½íŠ¸ ìë™ ìƒì„± ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ Ollamaë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”.

#### Windows
```bash
winget install Ollama.Ollama
```

ë˜ëŠ” https://ollama.com/download ì—ì„œ ì„¤ì¹˜ í”„ë¡œê·¸ë¨ ë‹¤ìš´ë¡œë“œ

#### macOS
```bash
brew install ollama
```

#### Linux
```bash
curl -fsSL https://ollama.com/install.sh | sh
```

**LLaMA 3.1 ëª¨ë¸ ë‹¤ìš´ë¡œë“œ:**
```bash
ollama pull llama3.1:8b
```

---

## âœ… ì„¤ì¹˜ ê²€ì¦

### ì‹œìŠ¤í…œ ì •ë³´ í™•ì¸
```bash
python scripts/install_models.py --verify
```

### ë°±ì—”ë“œ ì„œë²„ ì‹¤í–‰ í…ŒìŠ¤íŠ¸
```bash
cd backend
python app.py
```

ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:8000 ì ‘ì†í•˜ì—¬ í™•ì¸

**ì„±ê³µ ì‹œ ì¶œë ¥:**
```json
{
  "name": "Local AI Shorts Generator",
  "version": "0.1.0",
  "status": "running",
  "device": "cuda"
}
```

---

## ğŸ”§ ë¬¸ì œ í•´ê²°

### "CUDA not available" ì˜¤ë¥˜

**ì›ì¸:** GPU ë“œë¼ì´ë²„ ë˜ëŠ” CUDA ë²„ì „ ë¶ˆì¼ì¹˜

**í•´ê²°:**
1. NVIDIA ë“œë¼ì´ë²„ ìµœì‹  ë²„ì „ ì„¤ì¹˜: https://www.nvidia.com/drivers
2. PyTorch CUDA ë²„ì „ í™•ì¸:
   ```bash
   python -c "import torch; print(torch.version.cuda)"
   ```
3. ë§ëŠ” ë²„ì „ ì¬ì„¤ì¹˜

---

### "Out of Memory" ì˜¤ë¥˜

**ì›ì¸:** GPU VRAM ë¶€ì¡±

**í•´ê²°:**
1. ë‹¤ë¥¸ í”„ë¡œê·¸ë¨ ì¢…ë£Œ
2. ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°
3. í•´ìƒë„ ë‚®ì¶”ê¸°
4. ëª¨ë¸ ì–‘ìí™” ì‚¬ìš©

---

### ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ëŠë¦¼/ì‹¤íŒ¨

**ì›ì¸:** ë„¤íŠ¸ì›Œí¬ ë¬¸ì œ ë˜ëŠ” Hugging Face ì„œë²„ ë¶€í•˜

**í•´ê²°:**
1. VPN ì‚¬ìš© (ì¤‘êµ­/ì¼ë¶€ êµ­ê°€)
2. Hugging Face ë¯¸ëŸ¬ ì‚¬ìš©:
   ```bash
   export HF_ENDPOINT=https://hf-mirror.com
   ```
3. ë‹¤ì‹œ ì‹œë„

---

### FFmpeg ì˜¤ë¥˜

**ì›ì¸:** FFmpeg ë¯¸ì„¤ì¹˜

**í•´ê²°:**

#### Windows
```bash
# Chocolatey ì‚¬ìš©
choco install ffmpeg

# ë˜ëŠ” https://ffmpeg.org/download.html ì—ì„œ ë‹¤ìš´ë¡œë“œ
```

#### macOS
```bash
brew install ffmpeg
```

#### Linux
```bash
sudo apt install ffmpeg
```

---

## ğŸ“ ë‹¤ìŒ ë‹¨ê³„

ì„¤ì¹˜ ì™„ë£Œ í›„:

1. [ì‚¬ìš©ì ê°€ì´ë“œ](USER_GUIDE.md) ì½ê¸°
2. [API ë¬¸ì„œ](API.md) í™•ì¸
3. ì²« ì‡¼ì¸  ìƒì„±í•´ë³´ê¸°:
   ```bash
   cd backend
   python app.py
   
   # ë‹¤ë¥¸ í„°ë¯¸ë„ì—ì„œ
   curl -X POST http://localhost:8000/api/shorts/generate \
     -H "Content-Type: application/json" \
     -d '{"url": "https://example.com/product", "character_id": "executive-fox"}'
   ```

---

## ğŸ“ ë„ì›€ì´ í•„ìš”í•˜ì‹ ê°€ìš”?

- ğŸ“– [ë¬¸ì„œ](../README.md)
- ğŸ› [ì´ìŠˆ ë¦¬í¬íŠ¸](https://github.com/your-repo/issues)
- ğŸ’¬ [ë””ìŠ¤ì½”ë“œ ì»¤ë®¤ë‹ˆí‹°](https://discord.gg/your-invite)

---

**ì„¤ì¹˜ ì„±ê³µì„ ì¶•í•˜í•©ë‹ˆë‹¤!** ğŸ‰
