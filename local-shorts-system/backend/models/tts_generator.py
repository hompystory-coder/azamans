#!/usr/bin/env python3
"""
ğŸ™ï¸ Coqui TTS ìŒì„± í•©ì„± ëª¨ë¸
ë¡œì»¬ CPU/GPUì—ì„œ í•œêµ­ì–´ TTS ìƒì„±
"""

import torch
from TTS.api import TTS
from pathlib import Path
from typing import Optional
from loguru import logger
import time
import numpy as np

class TTSGenerator:
    """Coqui TTS ê¸°ë°˜ ìŒì„± í•©ì„±ê¸°"""
    
    def __init__(self, models_dir: Path, device: str = "cuda"):
        self.models_dir = models_dir
        self.device = device
        self.tts = None
        self.loaded = False
        
    def load_model(self, model_name: str = "tts_models/multilingual/multi-dataset/xtts_v2"):
        """TTS ëª¨ë¸ ë¡œë“œ
        
        Args:
            model_name: Coqui TTS ëª¨ë¸ ì´ë¦„
                - "tts_models/multilingual/multi-dataset/xtts_v2" (ì¶”ì²œ, í•œêµ­ì–´ ì§€ì›)
                - "tts_models/ko/kss/tacotron2-DDC" (í•œêµ­ì–´ ì „ìš©)
        """
        try:
            logger.info(f"ğŸ™ï¸ Loading TTS model: {model_name}")
            start_time = time.time()
            
            # TTS ëª¨ë¸ ë¡œë“œ
            self.tts = TTS(
                model_name=model_name,
                progress_bar=True,
                gpu=(self.device == "cuda")
            )
            
            load_time = time.time() - start_time
            logger.info(f"âœ… TTS model loaded in {load_time:.1f}s")
            self.loaded = True
            
            # ì§€ì› ì–¸ì–´ í™•ì¸
            if hasattr(self.tts, 'languages'):
                logger.info(f"   Supported languages: {self.tts.languages}")
            
        except Exception as e:
            logger.error(f"âŒ Failed to load TTS model: {str(e)}")
            raise
    
    def generate_speech(
        self,
        text: str,
        output_path: Optional[Path] = None,
        language: str = "ko",
        speaker: Optional[str] = None,
        speed: float = 1.0,
        emotion: str = "neutral"
    ) -> str:
        """í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜
        
        Args:
            text: ë³€í™˜í•  í…ìŠ¤íŠ¸
            output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ ìë™ ìƒì„±)
            language: ì–¸ì–´ ì½”ë“œ (ko, en, etc.)
            speaker: í™”ì ID (ëª¨ë¸ì— ë”°ë¼ ë‹¤ë¦„)
            speed: ì¬ìƒ ì†ë„ (1.0 = ë³´í†µ)
            emotion: ê°ì • (neutral, happy, sad, angry ë“±)
            
        Returns:
            ìƒì„±ëœ ìŒì„± íŒŒì¼ ê²½ë¡œ
        """
        if not self.loaded:
            raise RuntimeError("TTS model not loaded. Call load_model() first.")
        
        try:
            logger.info(f"ğŸ™ï¸ Generating speech: {text[:50]}...")
            logger.info(f"   Language: {language}, Speed: {speed}x")
            
            start_time = time.time()
            
            # ì¶œë ¥ ê²½ë¡œ ì„¤ì •
            if output_path is None:
                output_dir = self.models_dir.parent / "output" / "audio"
                output_dir.mkdir(parents=True, exist_ok=True)
                timestamp = int(time.time())
                output_path = output_dir / f"speech_{timestamp}.wav"
            
            # ìŒì„± ìƒì„±
            if hasattr(self.tts, 'tts_to_file'):
                # XTTS-v2 ë“± ë‹¤êµ­ì–´ ëª¨ë¸
                self.tts.tts_to_file(
                    text=text,
                    file_path=str(output_path),
                    language=language,
                    speaker=speaker,
                    speed=speed
                )
            else:
                # ë‹¨ì¼ ì–¸ì–´ ëª¨ë¸
                self.tts.tts_to_file(
                    text=text,
                    file_path=str(output_path)
                )
            
            gen_time = time.time() - start_time
            duration = self._get_audio_duration(output_path)
            
            logger.info(f"âœ… Generated speech in {gen_time:.1f}s")
            logger.info(f"   Duration: {duration:.1f}s")
            logger.info(f"   Saved: {output_path.name}")
            
            return str(output_path)
            
        except Exception as e:
            logger.error(f"âŒ Speech generation failed: {str(e)}")
            raise
    
    def generate_batch(
        self,
        texts: list[str],
        output_dir: Optional[Path] = None,
        **kwargs
    ) -> list[str]:
        """ì—¬ëŸ¬ í…ìŠ¤íŠ¸ë¥¼ ë°°ì¹˜ë¡œ ìŒì„± ìƒì„±
        
        Args:
            texts: ë³€í™˜í•  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
            output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
            **kwargs: generate_speechì˜ ì¶”ê°€ ì¸ì
            
        Returns:
            ìƒì„±ëœ ìŒì„± íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        """
        if output_dir is None:
            output_dir = self.models_dir.parent / "output" / "audio"
            output_dir.mkdir(parents=True, exist_ok=True)
        
        logger.info(f"ğŸ™ï¸ Batch generating {len(texts)} speeches")
        
        output_paths = []
        timestamp = int(time.time())
        
        for idx, text in enumerate(texts):
            output_path = output_dir / f"speech_{timestamp}_{idx}.wav"
            
            try:
                path = self.generate_speech(
                    text=text,
                    output_path=output_path,
                    **kwargs
                )
                output_paths.append(path)
            except Exception as e:
                logger.error(f"âŒ Failed to generate speech {idx}: {str(e)}")
                output_paths.append(None)
        
        success_count = sum(1 for p in output_paths if p is not None)
        logger.info(f"âœ… Batch generation complete: {success_count}/{len(texts)} succeeded")
        
        return output_paths
    
    def clone_voice(
        self,
        text: str,
        reference_audio: str,
        output_path: Optional[Path] = None,
        language: str = "ko"
    ) -> str:
        """ì°¸ì¡° ìŒì„±ì„ í´ë¡ í•˜ì—¬ ìƒˆë¡œìš´ ìŒì„± ìƒì„± (XTTS-v2 ì „ìš©)
        
        Args:
            text: ë³€í™˜í•  í…ìŠ¤íŠ¸
            reference_audio: ì°¸ì¡° ìŒì„± íŒŒì¼ ê²½ë¡œ
            output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
            language: ì–¸ì–´ ì½”ë“œ
            
        Returns:
            ìƒì„±ëœ ìŒì„± íŒŒì¼ ê²½ë¡œ
        """
        if not self.loaded:
            raise RuntimeError("TTS model not loaded.")
        
        try:
            logger.info(f"ğŸ™ï¸ Cloning voice from: {reference_audio}")
            
            start_time = time.time()
            
            if output_path is None:
                output_dir = self.models_dir.parent / "output" / "audio"
                output_dir.mkdir(parents=True, exist_ok=True)
                timestamp = int(time.time())
                output_path = output_dir / f"cloned_{timestamp}.wav"
            
            # ìŒì„± í´ë¡œë‹
            self.tts.tts_to_file(
                text=text,
                file_path=str(output_path),
                speaker_wav=reference_audio,
                language=language
            )
            
            gen_time = time.time() - start_time
            logger.info(f"âœ… Voice cloned in {gen_time:.1f}s")
            
            return str(output_path)
            
        except Exception as e:
            logger.error(f"âŒ Voice cloning failed: {str(e)}")
            raise
    
    def _get_audio_duration(self, audio_path: Path) -> float:
        """ì˜¤ë””ì˜¤ íŒŒì¼ ê¸¸ì´ ê°€ì ¸ì˜¤ê¸°"""
        try:
            import librosa
            duration = librosa.get_duration(path=str(audio_path))
            return duration
        except:
            # librosaê°€ ì—†ìœ¼ë©´ ëŒ€ëµì ì¸ ê³„ì‚°
            import wave
            try:
                with wave.open(str(audio_path), 'rb') as wf:
                    frames = wf.getnframes()
                    rate = wf.getframerate()
                    return frames / float(rate)
            except:
                return 0.0
    
    def unload_model(self):
        """ëª¨ë¸ ì–¸ë¡œë“œ"""
        if self.tts is not None:
            del self.tts
            self.tts = None
            
            if self.device == "cuda":
                torch.cuda.empty_cache()
            
            logger.info("ğŸ—‘ï¸ TTS model unloaded")
            self.loaded = False


# ========== ìºë¦­í„°ë³„ ìŒì„± ì„¤ì • ==========

CHARACTER_VOICES = {
    "executive-fox": {
        "language": "ko",
        "speaker": None,  # ê¸°ë³¸ í™”ì
        "speed": 1.0,
        "emotion": "professional"
    },
    "ceo-lion": {
        "language": "ko",
        "speaker": None,
        "speed": 0.95,  # ì•½ê°„ ëŠë¦¬ê²Œ (ê¶Œìœ„)
        "emotion": "powerful"
    },
    "tech-fox": {
        "language": "ko",
        "speaker": None,
        "speed": 1.1,  # ì•½ê°„ ë¹ ë¥´ê²Œ (í™œë°œ)
        "emotion": "energetic"
    },
    "fashionista-cat": {
        "language": "ko",
        "speaker": None,
        "speed": 1.05,
        "emotion": "elegant"
    },
    "comedian-parrot": {
        "language": "ko",
        "speaker": None,
        "speed": 1.2,  # ë¹ ë¥´ê²Œ (ì—ë„ˆì§€ ë„˜ì¹¨)
        "emotion": "funny"
    },
}

def get_voice_settings(character_id: str) -> dict:
    """ìºë¦­í„° IDë¡œ ìŒì„± ì„¤ì • ê°€ì ¸ì˜¤ê¸°"""
    return CHARACTER_VOICES.get(
        character_id,
        CHARACTER_VOICES["executive-fox"]  # ê¸°ë³¸ê°’
    )


# ========== í…ŒìŠ¤íŠ¸ ì½”ë“œ ==========
if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    models_dir = Path(__file__).parent.parent.parent / "models"
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    logger.info(f"ğŸ”§ Device: {device}")
    
    generator = TTSGenerator(models_dir, device)
    
    # ëª¨ë¸ ë¡œë“œ (ìµœì´ˆ 1íšŒ)
    # generator.load_model()
    
    # ìŒì„± ìƒì„± í…ŒìŠ¤íŠ¸
    # text = "ì•ˆë…•í•˜ì„¸ìš”! ì´ê·¸ì œíí‹°ë¸Œ í­ìŠ¤ì…ë‹ˆë‹¤. ì˜¤ëŠ˜ì€ í”„ë¦¬ë¯¸ì—„ ë¬´ì„  ì´ì–´í°ì„ ì†Œê°œí•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
    # audio_path = generator.generate_speech(text, language="ko")
    # print(f"Generated: {audio_path}")
