#!/usr/bin/env python3
"""
ğŸ¨ Stable Diffusion ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸
ë¡œì»¬ GPUì—ì„œ Pixar ìŠ¤íƒ€ì¼ ìºë¦­í„° ì´ë¯¸ì§€ ìƒì„±
"""

import torch
from diffusers import StableDiffusionXLPipeline, DPMSolverMultistepScheduler
from pathlib import Path
from typing import Optional, List
from loguru import logger
import time

class ImageGenerator:
    """Stable Diffusion ê¸°ë°˜ ì´ë¯¸ì§€ ìƒì„±ê¸°"""
    
    def __init__(self, models_dir: Path, device: str = "cuda"):
        self.models_dir = models_dir
        self.device = device
        self.pipe = None
        self.loaded = False
        
    def load_model(self, model_id: str = "stabilityai/stable-diffusion-xl-base-1.0"):
        """ëª¨ë¸ ë¡œë“œ"""
        try:
            logger.info(f"ğŸ¨ Loading Stable Diffusion XL from {model_id}")
            start_time = time.time()
            
            # íŒŒì´í”„ë¼ì¸ ë¡œë“œ
            self.pipe = StableDiffusionXLPipeline.from_pretrained(
                model_id,
                torch_dtype=torch.float16 if self.device == "cuda" else torch.float32,
                variant="fp16" if self.device == "cuda" else None,
                use_safetensors=True,
                cache_dir=self.models_dir
            )
            
            # GPUë¡œ ì´ë™
            if self.device == "cuda":
                self.pipe = self.pipe.to(self.device)
                
                # ë©”ëª¨ë¦¬ ìµœì í™”
                self.pipe.enable_attention_slicing()
                self.pipe.enable_vae_slicing()
                
                # xformers ì‚¬ìš© (ì„¤ì¹˜ë˜ì–´ ìˆë‹¤ë©´)
                try:
                    self.pipe.enable_xformers_memory_efficient_attention()
                    logger.info("âœ… xformers enabled for better performance")
                except:
                    logger.warning("âš ï¸ xformers not available, using default attention")
            
            # ìŠ¤ì¼€ì¤„ëŸ¬ ìµœì í™” (ì†ë„ í–¥ìƒ)
            self.pipe.scheduler = DPMSolverMultistepScheduler.from_config(
                self.pipe.scheduler.config
            )
            
            load_time = time.time() - start_time
            logger.info(f"âœ… Model loaded in {load_time:.1f}s")
            self.loaded = True
            
        except Exception as e:
            logger.error(f"âŒ Failed to load model: {str(e)}")
            raise
    
    def generate_character(
        self,
        character_id: str,
        prompt: str,
        negative_prompt: Optional[str] = None,
        num_images: int = 1,
        width: int = 1024,
        height: int = 1024,
        num_inference_steps: int = 30,
        guidance_scale: float = 7.5,
        seed: Optional[int] = None
    ) -> List[str]:
        """ìºë¦­í„° ì´ë¯¸ì§€ ìƒì„±
        
        Args:
            character_id: ìºë¦­í„° ID
            prompt: ìƒì„± í”„ë¡¬í”„íŠ¸
            negative_prompt: ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸
            num_images: ìƒì„±í•  ì´ë¯¸ì§€ ìˆ˜
            width: ì´ë¯¸ì§€ ë„ˆë¹„
            height: ì´ë¯¸ì§€ ë†’ì´
            num_inference_steps: ì¶”ë¡  ìŠ¤í… ìˆ˜ (ë†’ì„ìˆ˜ë¡ í’ˆì§ˆ â†‘, ì‹œê°„ â†‘)
            guidance_scale: ê°€ì´ë˜ìŠ¤ ìŠ¤ì¼€ì¼ (ë†’ì„ìˆ˜ë¡ í”„ë¡¬í”„íŠ¸ ë”°ë¦„)
            seed: ëœë¤ ì‹œë“œ (ì¬í˜„ì„±)
            
        Returns:
            ìƒì„±ëœ ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        """
        if not self.loaded:
            raise RuntimeError("Model not loaded. Call load_model() first.")
        
        try:
            logger.info(f"ğŸ¨ Generating {num_images} image(s) for {character_id}")
            logger.info(f"   Prompt: {prompt[:100]}...")
            
            start_time = time.time()
            
            # ì‹œë“œ ì„¤ì •
            generator = None
            if seed is not None:
                generator = torch.Generator(device=self.device).manual_seed(seed)
            
            # ê¸°ë³¸ ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸
            if negative_prompt is None:
                negative_prompt = (
                    "ugly, blurry, low quality, distorted, deformed, "
                    "bad anatomy, extra limbs, poorly drawn, "
                    "text, watermark, signature"
                )
            
            # ì´ë¯¸ì§€ ìƒì„±
            output = self.pipe(
                prompt=prompt,
                negative_prompt=negative_prompt,
                num_images_per_prompt=num_images,
                width=width,
                height=height,
                num_inference_steps=num_inference_steps,
                guidance_scale=guidance_scale,
                generator=generator
            )
            
            images = output.images
            
            # ì´ë¯¸ì§€ ì €ì¥
            output_dir = self.models_dir.parent / "output" / "images" / character_id
            output_dir.mkdir(parents=True, exist_ok=True)
            
            saved_paths = []
            timestamp = int(time.time())
            
            for idx, image in enumerate(images):
                filename = f"{character_id}_{timestamp}_{idx}.png"
                filepath = output_dir / filename
                image.save(filepath)
                saved_paths.append(str(filepath))
                logger.info(f"   ğŸ’¾ Saved: {filepath.name}")
            
            gen_time = time.time() - start_time
            logger.info(f"âœ… Generated {num_images} image(s) in {gen_time:.1f}s ({gen_time/num_images:.1f}s per image)")
            
            return saved_paths
            
        except Exception as e:
            logger.error(f"âŒ Image generation failed: {str(e)}")
            raise
    
    def unload_model(self):
        """ëª¨ë¸ ì–¸ë¡œë“œ (ë©”ëª¨ë¦¬ í•´ì œ)"""
        if self.pipe is not None:
            del self.pipe
            self.pipe = None
            
            if self.device == "cuda":
                torch.cuda.empty_cache()
            
            logger.info("ğŸ—‘ï¸ Model unloaded, memory freed")
            self.loaded = False


# ========== ìºë¦­í„° í”„ë¡¬í”„íŠ¸ ì„¤ì • ==========

CHARACTER_PROMPTS = {
    "executive-fox": (
        "Premium 3D rendered sophisticated fox in elegant business suit, "
        "gold-rimmed glasses, confident posture, studio lighting, "
        "Pixar-quality animation, 8K ultra detailed, professional business "
        "environment with luxury office background, sophisticated professional "
        "gestures with confident eye contact"
    ),
    "ceo-lion": (
        "Premium 3D rendered distinguished lion with magnificent golden mane, "
        "wearing luxury suit and tie, executive presence, cinematic studio lighting, "
        "Pixar-quality animation, 8K ultra detailed, prestigious office with city view, "
        "powerful confident movements with commanding presence"
    ),
    "tech-fox": (
        "Premium 3D rendered tech-savvy fox wearing AR smart glasses, "
        "modern tech hoodie, holding holographic tablet, futuristic lighting, "
        "Pixar-quality animation, 8K ultra detailed, high-tech laboratory with glowing screens, "
        "precise tech gestures with innovative hand movements"
    ),
    "fashionista-cat": (
        "Premium 3D rendered elegant Persian cat with silky white fur, "
        "wearing designer accessories, refined movements, cinematic lighting, "
        "Pixar-style animation, 8K resolution, luxury boutique background, "
        "graceful fluid movements with aristocratic poise"
    ),
    "athlete-cheetah": (
        "Premium 3D rendered athletic cheetah in sports gear, "
        "dynamic pose, energy trails, dramatic lighting, "
        "Pixar-quality animation, 8K ultra detailed, stadium background, "
        "powerful athletic movements with speed effects"
    ),
    "chef-penguin": (
        "Premium 3D rendered professional penguin chef with white chef hat, "
        "elegant cooking pose, warm kitchen lighting, "
        "Pixar-style rendering, 8K resolution, Michelin restaurant background, "
        "graceful cooking gestures with culinary expertise"
    ),
    "comedian-parrot": (
        "Premium 3D rendered colorful parrot comedian with microphone, "
        "expressive face, stage lighting, "
        "Pixar-quality animation, 8K ultra detailed, comedy club background, "
        "energetic entertaining movements with humorous expressions"
    ),
}

def get_character_prompt(character_id: str) -> str:
    """ìºë¦­í„° IDë¡œ í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°"""
    return CHARACTER_PROMPTS.get(
        character_id,
        CHARACTER_PROMPTS["executive-fox"]  # ê¸°ë³¸ê°’
    )


# ========== í…ŒìŠ¤íŠ¸ ì½”ë“œ ==========
if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    models_dir = Path(__file__).parent.parent.parent / "models"
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    logger.info(f"ğŸ”§ Device: {device}")
    
    generator = ImageGenerator(models_dir, device)
    
    # ëª¨ë¸ ë¡œë“œ (ìµœì´ˆ 1íšŒ, ìë™ ë‹¤ìš´ë¡œë“œ)
    # generator.load_model()
    
    # ì´ë¯¸ì§€ ìƒì„± í…ŒìŠ¤íŠ¸
    # prompt = get_character_prompt("executive-fox")
    # images = generator.generate_character(
    #     character_id="executive-fox",
    #     prompt=prompt,
    #     num_images=1,
    #     num_inference_steps=30
    # )
    # print(f"Generated: {images}")
