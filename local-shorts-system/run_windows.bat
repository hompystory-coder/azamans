@echo off
chcp 65001 > nul
title ë¡œì»¬ AI ì‡¼ì¸  ìƒì„± ì‹œìŠ¤í…œ

echo â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
echo   ðŸš€ ë¡œì»¬ PC AI ì‡¼ì¸  ìƒì„± ì‹œìŠ¤í…œ ì‹œìž‘
echo â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
echo.

REM Ollama ì„œë²„ ì‹œìž‘ (ë°±ê·¸ë¼ìš´ë“œ)
echo [1/2] Ollama ì„œë²„ ì‹œìž‘...
start /B ollama serve > nul 2>&1
timeout /t 3 /nobreak > nul
echo âœ… Ollama ì„œë²„ ì‹¤í–‰ ì¤‘
echo.

REM ê°€ìƒí™˜ê²½ í™œì„±í™”
call venv\Scripts\activate.bat

REM GPU í™•ì¸
echo [2/2] GPU í™•ì¸ ì¤‘...
python -c "import torch; print('âœ… GPU ì‚¬ìš© ê°€ëŠ¥' if torch.cuda.is_available() else 'âš ï¸ CPU ëª¨ë“œë¡œ ì‹¤í–‰')"
echo.

echo â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
echo   âœ… ì„œë²„ ì‹œìž‘ ì¤‘...
echo â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
echo.
echo ðŸ“‹ ì„œë²„ ì£¼ì†Œ: http://localhost:8000
echo ðŸ“š API ë¬¸ì„œ:  http://localhost:8000/docs
echo.
echo â¹ï¸  ì¢…ë£Œí•˜ë ¤ë©´ Ctrl+C ëˆ„ë¥´ì„¸ìš”
echo â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
echo.

REM FastAPI ì„œë²„ ì‹œìž‘
cd backend
python app.py

REM ì¢…ë£Œ ì‹œ Ollamaë„ ì¢…ë£Œ
taskkill /IM ollama.exe /F > nul 2>&1
