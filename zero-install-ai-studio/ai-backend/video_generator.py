"""
AI Video Generator API
ì´ë¯¸ì§€ë¥¼ ì‹¤ì œ ë¹„ë””ì˜¤ë¡œ ë³€í™˜
"""

from flask import Flask, request, jsonify, send_file
from flask_cors import CORS
from PIL import Image, ImageDraw, ImageFont, ImageFilter
from moviepy import ImageClip, concatenate_videoclips, AudioFileClip, CompositeVideoClip, TextClip, CompositeAudioClip
import io
import os
import logging
from datetime import datetime
import requests
import numpy as np

app = Flask(__name__)
CORS(app)

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ìƒì„±ëœ íŒŒì¼ ì €ì¥ ë””ë ‰í† ë¦¬
OUTPUT_DIR = '/home/azamans/webapp/zero-install-ai-studio/public/generated'
VIDEO_DIR = '/home/azamans/webapp/zero-install-ai-studio/public/videos'
os.makedirs(OUTPUT_DIR, exist_ok=True)
os.makedirs(VIDEO_DIR, exist_ok=True)

def create_beautiful_image(prompt, width=1080, height=1920, style="traditional"):
    """
    ê³ í’ˆì§ˆ ì´ë¯¸ì§€ ìƒì„±
    """
    try:
        img = Image.new('RGB', (width, height), color='white')
        draw = ImageDraw.Draw(img)
        
        # ìŠ¤íƒ€ì¼ë³„ ë°°ê²½ ìƒì„±
        if style == "traditional":
            colors = [
                (139, 115, 85),   # ê°ˆìƒ‰
                (212, 175, 55),   # ê¸ˆìƒ‰
                (44, 95, 45),     # ë…¹ìƒ‰
                (151, 188, 98),   # ì—°ë‘ìƒ‰
            ]
        elif style == "modern":
            colors = [
                (102, 102, 255),  # ë³´ë¼
                (255, 102, 178),  # ë¶„í™
                (102, 255, 255),  # ì²­ë¡
            ]
        else:
            colors = [
                (100, 100, 150),
                (150, 100, 200),
            ]
        
        # ê·¸ë¼ë°ì´ì…˜ ë°°ê²½
        for y in range(height):
            progress = y / height
            color_idx = int(progress * (len(colors) - 1))
            color_idx = min(color_idx, len(colors) - 2)
            
            next_color_progress = (progress * (len(colors) - 1)) - color_idx
            
            r = int(colors[color_idx][0] + (colors[color_idx + 1][0] - colors[color_idx][0]) * next_color_progress)
            g = int(colors[color_idx][1] + (colors[color_idx + 1][1] - colors[color_idx][1]) * next_color_progress)
            b = int(colors[color_idx][2] + (colors[color_idx + 1][2] - colors[color_idx][2]) * next_color_progress)
            
            draw.rectangle([(0, y), (width, y + 1)], fill=(r, g, b))
        
        # í…ìŠ¤ì²˜ ì¶”ê°€
        img = img.filter(ImageFilter.GaussianBlur(radius=2))
        
        # í”„ë¡¬í”„íŠ¸ í…ìŠ¤íŠ¸ ì¶”ê°€
        try:
            font_large = ImageFont.truetype("/usr/share/fonts/truetype/nanum/NanumGothicBold.ttf", 70)
            font_medium = ImageFont.truetype("/usr/share/fonts/truetype/nanum/NanumGothic.ttf", 40)
        except:
            font_large = ImageFont.load_default()
            font_medium = ImageFont.load_default()
        
        # ì¤‘ì•™ì— í…ìŠ¤íŠ¸
        words = prompt.split(' ')
        lines = []
        current_line = []
        
        for word in words:
            current_line.append(word)
            test_line = ' '.join(current_line)
            bbox = draw.textbbox((0, 0), test_line, font=font_medium)
            if bbox[2] - bbox[0] > width - 200 and len(current_line) > 1:
                current_line.pop()
                if current_line:
                    lines.append(' '.join(current_line))
                current_line = [word]
        
        if current_line:
            lines.append(' '.join(current_line))
        
        # í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
        y_offset = (height - len(lines) * 60) // 2
        
        for line in lines:
            bbox = draw.textbbox((0, 0), line, font=font_medium)
            text_width = bbox[2] - bbox[0]
            x = (width - text_width) // 2
            
            # ê·¸ë¦¼ì
            draw.text((x + 3, y_offset + 3), line, font=font_medium, fill=(0, 0, 0, 128))
            # í…ìŠ¤íŠ¸
            draw.text((x, y_offset), line, font=font_medium, fill=(255, 255, 255))
            
            y_offset += 60
        
        # ì¥ì‹ ì¶”ê°€
        draw.ellipse([(width//2 - 100, 100), (width//2 + 100, 300)], 
                     outline=(255, 255, 255, 200), width=5)
        draw.ellipse([(width//2 - 100, height - 300), (width//2 + 100, height - 100)], 
                     outline=(255, 255, 255, 200), width=5)
        
        return img
    
    except Exception as e:
        logger.error(f"Error creating image: {e}")
        img = Image.new('RGB', (width, height), color=(100, 100, 150))
        draw = ImageDraw.Draw(img)
        draw.text((width//2 - 100, height//2), "Image Generation", fill=(255, 255, 255))
        return img

def apply_camera_effect(clip, camera_movement, duration):
    """
    ì¹´ë©”ë¼ íš¨ê³¼ ì ìš©
    
    ì§€ì› íš¨ê³¼:
    - zoom_in: ì¤Œ ì¸
    - zoom_out: ì¤Œ ì•„ì›ƒ
    - pan_left: ì™¼ìª½ìœ¼ë¡œ íŒ¨ë‹
    - pan_right: ì˜¤ë¥¸ìª½ìœ¼ë¡œ íŒ¨ë‹
    - dolly_forward: ì „ì§„ (ì¤Œ ì¸ê³¼ ìœ ì‚¬)
    - dolly_backward: í›„ì§„ (ì¤Œ ì•„ì›ƒê³¼ ìœ ì‚¬)
    - tilt_up: ìœ„ë¡œ í‹¸íŠ¸
    - tilt_down: ì•„ë˜ë¡œ í‹¸íŠ¸
    - crane_up: í¬ë ˆì¸ ì—…
    - crane_down: í¬ë ˆì¸ ë‹¤ìš´
    """
    try:
        w, h = clip.size
        
        # ì¤Œ íš¨ê³¼
        if camera_movement in ['zoom_in', 'dolly_forward', 'push_in']:
            def zoom_effect(get_frame, t):
                frame = get_frame(t)
                progress = t / duration
                zoom_factor = 1.0 + (0.3 * progress)  # 1.0 â†’ 1.3ë°° ì¤Œ
                
                # ì¤‘ì•™ì„ ê¸°ì¤€ìœ¼ë¡œ ì¤Œ
                new_w = int(w / zoom_factor)
                new_h = int(h / zoom_factor)
                x_offset = (w - new_w) // 2
                y_offset = (h - new_h) // 2
                
                cropped = frame[y_offset:y_offset+new_h, x_offset:x_offset+new_w]
                
                # ì›ë³¸ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
                from PIL import Image
                img = Image.fromarray(cropped)
                img = img.resize((w, h), Image.Resampling.LANCZOS)
                return np.array(img)
            
            return clip.transform(zoom_effect)
        
        elif camera_movement in ['zoom_out', 'dolly_backward', 'pull_back', 'slow_zoom_out']:
            def zoom_out_effect(get_frame, t):
                frame = get_frame(t)
                progress = t / duration
                zoom_factor = 1.3 - (0.3 * progress)  # 1.3ë°° â†’ 1.0ë°° ì¤Œ
                
                new_w = int(w / zoom_factor)
                new_h = int(h / zoom_factor)
                x_offset = (w - new_w) // 2
                y_offset = (h - new_h) // 2
                
                cropped = frame[y_offset:y_offset+new_h, x_offset:x_offset+new_w]
                
                from PIL import Image
                img = Image.fromarray(cropped)
                img = img.resize((w, h), Image.Resampling.LANCZOS)
                return np.array(img)
            
            return clip.transform(zoom_out_effect)
        
        # íŒ¨ë‹ íš¨ê³¼
        elif camera_movement in ['pan_left', 'dolly_left']:
            def pan_left_effect(get_frame, t):
                frame = get_frame(t)
                progress = t / duration
                x_shift = int(w * 0.2 * progress)  # ìµœëŒ€ 20% ì´ë™
                
                # ì˜¤ë¥¸ìª½ì—ì„œ ì™¼ìª½ìœ¼ë¡œ ì´ë™
                result = np.zeros_like(frame)
                if x_shift < w:
                    result[:, :w-x_shift] = frame[:, x_shift:]
                return result
            
            return clip.transform(pan_left_effect)
        
        elif camera_movement in ['pan_right', 'dolly_right', 'pan_right_smooth']:
            def pan_right_effect(get_frame, t):
                frame = get_frame(t)
                progress = t / duration
                x_shift = int(w * 0.2 * progress)
                
                result = np.zeros_like(frame)
                if x_shift < w:
                    result[:, x_shift:] = frame[:, :w-x_shift]
                return result
            
            return clip.transform(pan_right_effect)
        
        # í‹¸íŠ¸ íš¨ê³¼
        elif camera_movement in ['tilt_up', 'crane_up']:
            def tilt_up_effect(get_frame, t):
                frame = get_frame(t)
                progress = t / duration
                y_shift = int(h * 0.2 * progress)
                
                result = np.zeros_like(frame)
                if y_shift < h:
                    result[:h-y_shift, :] = frame[y_shift:, :]
                return result
            
            return clip.transform(tilt_up_effect)
        
        elif camera_movement in ['tilt_down', 'crane_down']:
            def tilt_down_effect(get_frame, t):
                frame = get_frame(t)
                progress = t / duration
                y_shift = int(h * 0.2 * progress)
                
                result = np.zeros_like(frame)
                if y_shift < h:
                    result[y_shift:, :] = frame[:h-y_shift, :]
                return result
            
            return clip.transform(tilt_down_effect)
        
        # ê¸°ë³¸: íš¨ê³¼ ì—†ìŒ
        else:
            return clip
    
    except Exception as e:
        logger.warning(f"Failed to apply camera effect '{camera_movement}': {e}")
        return clip

def create_video_from_images(images_data, output_path, fps=30, background_music_url=None):
    """
    ì´ë¯¸ì§€ë“¤ì„ ë¹„ë””ì˜¤ë¡œ ë³€í™˜ (ì¹´ë©”ë¼ íš¨ê³¼ + ë°°ê²½ìŒì•… í¬í•¨)
    
    Args:
        images_data: ì”¬ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        output_path: ì¶œë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ
        fps: í”„ë ˆì„ë ˆì´íŠ¸
        background_music_url: ë°°ê²½ìŒì•… URL (ì„ íƒ ì‚¬í•­)
    """
    try:
        clips = []
        
        for i, img_data in enumerate(images_data):
            # ì´ë¯¸ì§€ ë¡œë“œ
            if 'image_path' in img_data:
                img_path = img_data['image_path']
                if not os.path.exists(img_path):
                    logger.warning(f"Image not found: {img_path}")
                    continue
            else:
                # ì´ë¯¸ì§€ ìƒì„±
                img = create_beautiful_image(
                    img_data.get('description', ''),
                    width=1080,
                    height=1920,
                    style=img_data.get('style', 'traditional')
                )
                # ì„ì‹œ ì €ì¥
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                img_path = os.path.join(OUTPUT_DIR, f'temp_scene_{i}_{timestamp}.png')
                img.save(img_path, 'PNG', quality=95)
            
            # ì§€ì† ì‹œê°„
            duration = img_data.get('duration', 3)
            
            # ì˜¤ë””ì˜¤ ë¨¼ì € í™•ì¸ (audio_urlì´ ìˆëŠ” ê²½ìš°)
            audio_clip = None
            if 'audio_url' in img_data and img_data['audio_url']:
                audio_url = img_data['audio_url']
                # /audio/xxx.mp3 â†’ ì‹¤ì œ íŒŒì¼ ê²½ë¡œë¡œ ë³€í™˜
                if audio_url.startswith('/audio/'):
                    audio_filename = audio_url.replace('/audio/', '')
                    audio_path = os.path.join('/home/azamans/webapp/zero-install-ai-studio/public/audio', audio_filename)
                    
                    if os.path.exists(audio_path):
                        try:
                            audio_clip = AudioFileClip(audio_path)
                            # ì˜¤ë””ì˜¤ ê¸¸ì´ê°€ ìˆìœ¼ë©´ ê·¸ ê¸¸ì´ë¥¼ durationìœ¼ë¡œ ì‚¬ìš©
                            if audio_clip.duration > 0:
                                duration = audio_clip.duration
                                logger.info(f"  â†’ Using audio duration: {audio_clip.duration:.1f}s for {audio_filename}")
                        except Exception as e:
                            logger.warning(f"  â†’ Failed to load audio: {e}")
                            audio_clip = None
                    else:
                        logger.warning(f"  â†’ Audio file not found: {audio_path}")
            
            # ImageClip ìƒì„± (duration ëª…ì‹œ)
            clip = ImageClip(img_path, duration=duration)
            
            # ğŸ†• ì¹´ë©”ë¼ íš¨ê³¼ ì ìš©
            camera_movement = img_data.get('camera_movement', None)
            if camera_movement:
                logger.info(f"  â†’ Applying camera effect: {camera_movement}")
                clip = apply_camera_effect(clip, camera_movement, duration)
            
            # ì˜¤ë””ì˜¤ ì¶”ê°€
            if audio_clip is not None:
                try:
                    clip = clip.with_audio(audio_clip)
                    logger.info(f"  â†’ Audio successfully attached!")
                except Exception as e:
                    logger.warning(f"  â†’ Failed to attach audio: {e}")
            
            clips.append(clip)
            logger.info(f"Processed scene {i+1}/{len(images_data)}")
        
        if not clips:
            raise Exception("No valid clips created")
        
        # ëª¨ë“  í´ë¦½ ì—°ê²°
        logger.info("Concatenating clips...")
        final_clip = concatenate_videoclips(clips, method="compose")
        
        # ğŸ†• ë°°ê²½ìŒì•… ì¶”ê°€
        if background_music_url:
            logger.info(f"Adding background music: {background_music_url}")
            try:
                # ë°°ê²½ìŒì•… ë¡œë“œ
                bgm_path = None
                if background_music_url.startswith('http'):
                    # URLì¸ ê²½ìš° ë‹¤ìš´ë¡œë“œ
                    import requests
                    response = requests.get(background_music_url, timeout=10)
                    if response.status_code == 200:
                        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                        bgm_path = f'/tmp/bgm_{timestamp}.mp3'
                        with open(bgm_path, 'wb') as f:
                            f.write(response.content)
                        logger.info(f"  â†’ Downloaded BGM to: {bgm_path}")
                elif background_music_url.startswith('/'):
                    # ë¡œì»¬ íŒŒì¼ ê²½ë¡œ
                    bgm_path = background_music_url
                
                if bgm_path and os.path.exists(bgm_path):
                    bgm_clip = AudioFileClip(bgm_path)
                    
                    # ë°°ê²½ìŒì•… ê¸¸ì´ ì¡°ì • (ë¹„ë””ì˜¤ ê¸¸ì´ì— ë§ì¶¤)
                    video_duration = final_clip.duration
                    if bgm_clip.duration < video_duration:
                        # ë°°ê²½ìŒì•…ì´ ì§§ìœ¼ë©´ ë°˜ë³µ
                        logger.info(f"  â†’ Looping BGM (original: {bgm_clip.duration:.1f}s, needed: {video_duration:.1f}s)")
                        num_loops = int(video_duration / bgm_clip.duration) + 1
                        bgm_clip = bgm_clip.loop(n=num_loops).subclipped(0, video_duration)
                    elif bgm_clip.duration > video_duration:
                        # ë°°ê²½ìŒì•…ì´ ê¸¸ë©´ ìë¥´ê¸°
                        logger.info(f"  â†’ Trimming BGM (original: {bgm_clip.duration:.1f}s, needed: {video_duration:.1f}s)")
                        bgm_clip = bgm_clip.subclipped(0, video_duration)
                    
                    # ë°°ê²½ìŒì•… ë³¼ë¥¨ ì¡°ì ˆ (30%ë¡œ ë‚®ì¶¤)
                    bgm_clip = bgm_clip.with_effects([("audio_fadein", 1.0), ("audio_fadeout", 1.0)])
                    bgm_clip = bgm_clip.multiply_volume(0.3)
                    
                    # ê¸°ì¡´ ì˜¤ë””ì˜¤ì™€ ë°°ê²½ìŒì•… ë¯¹ì‹±
                    if final_clip.audio is not None:
                        logger.info("  â†’ Mixing narration + BGM")
                        mixed_audio = CompositeAudioClip([final_clip.audio, bgm_clip])
                        final_clip = final_clip.with_audio(mixed_audio)
                    else:
                        logger.info("  â†’ Adding BGM only (no narration)")
                        final_clip = final_clip.with_audio(bgm_clip)
                    
                    logger.info("  âœ… Background music added successfully!")
                else:
                    logger.warning(f"  âš ï¸ BGM file not found: {bgm_path}")
                    
            except Exception as e:
                logger.warning(f"  âš ï¸ Failed to add background music: {e}")
                import traceback
                traceback.print_exc()
        
        # ë¹„ë””ì˜¤ ì €ì¥
        logger.info(f"Writing video to {output_path}...")
        final_clip.write_videofile(
            output_path,
            fps=fps,
            codec='libx264',
            audio_codec='aac',
            temp_audiofile=f'/tmp/temp_audio_{datetime.now().strftime("%Y%m%d_%H%M%S")}.m4a',
            remove_temp=True,
            threads=4,
            preset='ultrafast'
        )
        
        # í´ë¦½ ì •ë¦¬
        for clip in clips:
            clip.close()
        final_clip.close()
        
        logger.info("Video creation completed!")
        return True
        
    except Exception as e:
        logger.error(f"Error creating video: {e}")
        import traceback
        traceback.print_exc()
        return False

@app.route('/health', methods=['GET'])
def health():
    """í—¬ìŠ¤ ì²´í¬"""
    return jsonify({
        'status': 'healthy',
        'service': 'video-generator',
        'timestamp': datetime.now().isoformat()
    })

@app.route('/generate-image', methods=['POST'])
def generate_image():
    """ë‹¨ì¼ ì´ë¯¸ì§€ ìƒì„± API"""
    try:
        data = request.json
        prompt = data.get('prompt', 'Beautiful landscape')
        width = data.get('width', 1080)
        height = data.get('height', 1920)
        style = data.get('style', 'traditional')
        
        logger.info(f"Generating image for prompt: {prompt}")
        
        # ì´ë¯¸ì§€ ìƒì„±
        image = create_beautiful_image(prompt, width, height, style)
        
        # ì €ì¥
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"generated_{timestamp}.png"
        filepath = os.path.join(OUTPUT_DIR, filename)
        image.save(filepath, 'PNG', quality=95)
        
        # URL ë°˜í™˜
        image_url = f"/generated/{filename}"
        
        return jsonify({
            'success': True,
            'image_url': image_url,
            'filename': filename,
            'width': width,
            'height': height
        })
    
    except Exception as e:
        logger.error(f"Error generating image: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/generate-video', methods=['POST'])
def generate_video():
    """
    ì´ë¯¸ì§€ë“¤ì„ ë¹„ë””ì˜¤ë¡œ ë³€í™˜í•˜ëŠ” API
    """
    try:
        data = request.json
        title = data.get('title', 'ìŠ¤í† ë¦¬')
        scenes = data.get('scenes', [])
        fps = data.get('fps', 30)
        background_music_url = data.get('background_music_url', None)  # ğŸ†• ë°°ê²½ìŒì•… URL
        
        if not scenes:
            return jsonify({
                'success': False,
                'error': 'No scenes provided'
            }), 400
        
        logger.info(f"Generating video for: {title} ({len(scenes)} scenes)")
        if background_music_url:
            logger.info(f"  ğŸµ Background music URL received: {background_music_url}")
        else:
            logger.warning(f"  âš ï¸ No background music URL provided")
        
        # scene_numberë¡œ ì •ë ¬ (ìˆëŠ” ê²½ìš°)
        if scenes and 'scene_number' in scenes[0]:
            scenes = sorted(scenes, key=lambda x: x.get('scene_number', 0))
            logger.info(f"Sorted scenes by scene_number")
        
        # ë¹„ë””ì˜¤ íŒŒì¼ëª…
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        safe_title = "".join(c for c in title if c.isalnum() or c in (' ', '-', '_')).strip()
        video_filename = f"{safe_title}_{timestamp}.mp4"
        output_path = os.path.join(VIDEO_DIR, video_filename)
        
        # scenes ë°ì´í„° ë³€í™˜ (image_urlì„ ì‹¤ì œ íŒŒì¼ ê²½ë¡œë¡œ)
        processed_scenes = []
        for scene in scenes:
            scene_data = dict(scene)
            
            # image_urlì„ ì‹¤ì œ íŒŒì¼ ê²½ë¡œë¡œ ë³€í™˜
            if 'image_url' in scene_data:
                image_url = scene_data['image_url']
                # /generated/xxx.png â†’ /home/azamans/webapp/zero-install-ai-studio/public/generated/xxx.png
                if image_url.startswith('/generated/'):
                    image_filename = image_url.replace('/generated/', '')
                    scene_data['image_path'] = os.path.join(OUTPUT_DIR, image_filename)
                elif image_url.startswith('/videos/'):
                    image_filename = image_url.replace('/videos/', '')
                    scene_data['image_path'] = os.path.join(VIDEO_DIR, image_filename)
                else:
                    # ì ˆëŒ€ ê²½ë¡œì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ì‚¬ìš©
                    scene_data['image_path'] = image_url
                    
                logger.info(f"Scene {len(processed_scenes)+1}: {scene_data.get('image_path', 'N/A')}")
            
            processed_scenes.append(scene_data)
        
        # ë¹„ë””ì˜¤ ìƒì„± (ğŸ†• ë°°ê²½ìŒì•… í¬í•¨)
        success = create_video_from_images(
            processed_scenes, 
            output_path, 
            fps, 
            background_music_url=background_music_url
        )
        
        if not success:
            return jsonify({
                'success': False,
                'error': 'Video creation failed'
            }), 500
        
        # íŒŒì¼ í¬ê¸° í™•ì¸
        file_size = os.path.getsize(output_path)
        
        video_url = f"/videos/{video_filename}"
        
        return jsonify({
            'success': True,
            'video_url': video_url,
            'filename': video_filename,
            'file_size': file_size,
            'duration': sum(s.get('duration', 3) for s in scenes),
            'scenes_count': len(scenes)
        })
    
    except Exception as e:
        logger.error(f"Error generating video: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/download/<filename>', methods=['GET'])
def download_file(filename):
    """íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
    try:
        # ë¹„ë””ì˜¤ íŒŒì¼ í™•ì¸
        video_path = os.path.join(VIDEO_DIR, filename)
        if os.path.exists(video_path):
            return send_file(video_path, as_attachment=True)
        
        # ì´ë¯¸ì§€ íŒŒì¼ í™•ì¸
        image_path = os.path.join(OUTPUT_DIR, filename)
        if os.path.exists(image_path):
            return send_file(image_path, as_attachment=True)
        
        return jsonify({'error': 'File not found'}), 404
    
    except Exception as e:
        logger.error(f"Error downloading file: {e}")
        return jsonify({'error': str(e)}), 500

if __name__ == '__main__':
    logger.info("Starting AI Video Generator API on port 5003...")
    app.run(host='0.0.0.0', port=5003, debug=False, threaded=True)
