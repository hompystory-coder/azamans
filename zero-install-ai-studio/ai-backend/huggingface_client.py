"""
Hugging Face Inference API Client
ì™„ì „ ë¬´ë£Œ (ë¬´ì œí•œ), ê³„ì •ë§Œ í•„ìš”
ì†ë„: ëŠë¦¼ (ëŒ€ê¸°ì—´ ë°©ì‹), ê°œë°œ/í…ŒìŠ¤íŠ¸ìš© ìµœì 
"""

import os
import requests
import logging
import time
from typing import Optional

logger = logging.getLogger(__name__)


class HuggingFaceClient:
    """Hugging Face Inference API í´ë¼ì´ì–¸íŠ¸"""
    
    # ì¶”ì²œ ëª¨ë¸ë“¤
    MODELS = {
        "sdxl": "stabilityai/stable-diffusion-xl-base-1.0",
        "sd15": "runwayml/stable-diffusion-v1-5",
        "sd21": "stabilityai/stable-diffusion-2-1",
    }
    
    def __init__(self, api_token: Optional[str] = None):
        """
        ì´ˆê¸°í™”
        
        Args:
            api_token: Hugging Face API í† í° (ì—†ìœ¼ë©´ í™˜ê²½ë³€ìˆ˜ HF_TOKEN ì‚¬ìš©)
                      https://huggingface.co/settings/tokens ì—ì„œ ë°œê¸‰
        """
        self.api_token = api_token or os.getenv("HF_TOKEN") or os.getenv("HUGGINGFACE_TOKEN")
        
        if not self.api_token:
            logger.warning("âš ï¸ HF_TOKEN ë¯¸ì„¤ì • - Hugging Face API ì‚¬ìš© ë¶ˆê°€")
            logger.info("ğŸ’¡ https://huggingface.co/settings/tokens ì—ì„œ í† í° ë°œê¸‰ í›„ ì„¤ì •")
            self.enabled = False
        else:
            self.enabled = True
            logger.info("âœ… Hugging Face API í™œì„±í™” (ì™„ì „ ë¬´ë£Œ)")
    
    def generate_image(
        self, 
        prompt: str,
        model: str = "sdxl",
        max_wait_time: int = 300,
        check_interval: int = 5
    ) -> Optional[bytes]:
        """
        ì´ë¯¸ì§€ ìƒì„± (ëŒ€ê¸°ì—´ ë°©ì‹)
        
        Args:
            prompt: ì˜ì–´ í”„ë¡¬í”„íŠ¸
            model: 'sdxl', 'sd15', 'sd21'
            max_wait_time: ìµœëŒ€ ëŒ€ê¸° ì‹œê°„ (ì´ˆ, ê¸°ë³¸ 300ì´ˆ=5ë¶„)
            check_interval: ìƒíƒœ í™•ì¸ ê°„ê²© (ì´ˆ, ê¸°ë³¸ 5ì´ˆ)
            
        Returns:
            ìƒì„±ëœ ì´ë¯¸ì§€ ë°”ì´íŠ¸ (ì‹¤íŒ¨ ì‹œ None)
        """
        if not self.enabled:
            logger.error("âŒ Hugging Face API ë¯¸í™œì„±í™”")
            return None
        
        model_id = self.MODELS.get(model, self.MODELS["sdxl"])
        api_url = f"https://api-inference.huggingface.co/models/{model_id}"
        
        headers = {"Authorization": f"Bearer {self.api_token}"}
        payload = {"inputs": prompt}
        
        try:
            logger.info(f"ğŸ¨ HuggingFace ì´ë¯¸ì§€ ìƒì„± ì¤‘: {prompt[:50]}...")
            logger.info(f"â³ ëŒ€ê¸°ì—´ ë°©ì‹ - ìµœëŒ€ {max_wait_time}ì´ˆ ëŒ€ê¸°")
            
            start_time = time.time()
            
            while True:
                response = requests.post(api_url, headers=headers, json=payload, timeout=30)
                
                # ì„±ê³µ
                if response.status_code == 200:
                    elapsed = time.time() - start_time
                    logger.info(f"âœ… ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ ({elapsed:.1f}ì´ˆ ì†Œìš”)")
                    return response.content
                
                # ëª¨ë¸ ë¡œë”© ì¤‘ (ëŒ€ê¸°ì—´)
                elif response.status_code == 503:
                    elapsed = time.time() - start_time
                    
                    if elapsed > max_wait_time:
                        logger.error(f"âŒ ì‹œê°„ ì´ˆê³¼ ({max_wait_time}ì´ˆ)")
                        return None
                    
                    try:
                        error_data = response.json()
                        estimated_time = error_data.get("estimated_time", "ì•Œ ìˆ˜ ì—†ìŒ")
                        logger.info(f"â³ ëª¨ë¸ ë¡œë”© ì¤‘... ì˜ˆìƒ ëŒ€ê¸° ì‹œê°„: {estimated_time}ì´ˆ")
                    except:
                        logger.info(f"â³ ëŒ€ê¸° ì¤‘... ({elapsed:.0f}/{max_wait_time}ì´ˆ)")
                    
                    time.sleep(check_interval)
                    continue
                
                # ê¸°íƒ€ ì˜¤ë¥˜
                else:
                    logger.error(f"âŒ ì˜¤ë¥˜: {response.status_code} - {response.text}")
                    return None
                    
        except Exception as e:
            logger.error(f"âŒ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def save_image(self, image_bytes: bytes, save_path: str) -> bool:
        """
        ì´ë¯¸ì§€ ë°”ì´íŠ¸ë¥¼ íŒŒì¼ë¡œ ì €ì¥
        
        Args:
            image_bytes: ì´ë¯¸ì§€ ë°”ì´íŠ¸ ë°ì´í„°
            save_path: ì €ì¥í•  ë¡œì»¬ ê²½ë¡œ
            
        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        try:
            with open(save_path, 'wb') as f:
                f.write(image_bytes)
            
            logger.info(f"âœ… ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {save_path}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    def generate_and_save(
        self, 
        prompt: str, 
        save_path: str,
        model: str = "sdxl"
    ) -> bool:
        """
        ì´ë¯¸ì§€ ìƒì„±í•˜ê³  ë°”ë¡œ ì €ì¥
        
        Args:
            prompt: ì˜ì–´ í”„ë¡¬í”„íŠ¸
            save_path: ì €ì¥ ê²½ë¡œ
            model: ëª¨ë¸ ì„ íƒ
            
        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        image_bytes = self.generate_image(prompt, model)
        
        if image_bytes:
            return self.save_image(image_bytes, save_path)
        
        return False
    
    def generate_batch(
        self, 
        prompts: list[str],
        model: str = "sdxl",
        max_wait_per_image: int = 300
    ) -> list[Optional[bytes]]:
        """
        ì—¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ìƒì„±
        
        Args:
            prompts: í”„ë¡¬í”„íŠ¸ ë¦¬ìŠ¤íŠ¸
            model: ëª¨ë¸ ì„ íƒ
            max_wait_per_image: ì´ë¯¸ì§€ë‹¹ ìµœëŒ€ ëŒ€ê¸° ì‹œê°„
            
        Returns:
            ìƒì„±ëœ ì´ë¯¸ì§€ ë°”ì´íŠ¸ ë¦¬ìŠ¤íŠ¸
        """
        results = []
        
        for i, prompt in enumerate(prompts, 1):
            logger.info(f"ğŸ“¸ ë°°ì¹˜ ìƒì„± {i}/{len(prompts)}")
            
            image_bytes = self.generate_image(
                prompt, 
                model=model,
                max_wait_time=max_wait_per_image
            )
            
            results.append(image_bytes)
            
            # API ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ì§§ì€ ëŒ€ê¸°
            if i < len(prompts):
                time.sleep(2)
        
        success_count = sum(1 for img in results if img is not None)
        logger.info(f"âœ… ë°°ì¹˜ ìƒì„± ì™„ë£Œ: {success_count}/{len(prompts)} ì„±ê³µ")
        
        return results


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    client = HuggingFaceClient()
    
    if client.enabled:
        # í…ŒìŠ¤íŠ¸ 1: ë‹¨ì¼ ì´ë¯¸ì§€ ìƒì„±
        print("\n=== í…ŒìŠ¤íŠ¸ 1: SDXL ì´ë¯¸ì§€ ìƒì„± ===")
        image_bytes = client.generate_image(
            prompt="a beautiful sunset over the ocean, cinematic lighting",
            model="sdxl"
        )
        
        if image_bytes:
            client.save_image(image_bytes, "/tmp/hf_test_sunset.png")
            print(f"âœ… ì´ë¯¸ì§€ ì €ì¥: /tmp/hf_test_sunset.png")
        
        # í…ŒìŠ¤íŠ¸ 2: ë°°ì¹˜ ìƒì„±
        print("\n=== í…ŒìŠ¤íŠ¸ 2: ë°°ì¹˜ ì´ë¯¸ì§€ ìƒì„± ===")
        prompts = [
            "a mountain landscape at sunrise",
            "a cozy coffee shop interior"
        ]
        
        batch_results = client.generate_batch(prompts, model="sdxl")
        
        for i, img_bytes in enumerate(batch_results, 1):
            if img_bytes:
                path = f"/tmp/hf_batch_{i}.png"
                client.save_image(img_bytes, path)
                print(f"âœ… ì´ë¯¸ì§€ {i} ì €ì¥: {path}")
    else:
        print("âŒ HF_TOKEN í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”!")
        print("1. https://huggingface.co/settings/tokens ì—ì„œ í† í° ë°œê¸‰")
        print("2. export HF_TOKEN='your_token_here'")
