/**
 * AI Engine Core - Browser-based AI Image Generation
 * ì²œì¬ì  ì‹œìŠ¤í…œì˜ í•µì‹¬: ë¸Œë¼ìš°ì €ì—ì„œ ì§„ì§œ AI ì‹¤í–‰
 */

// ONNX Runtimeì€ í˜„ì¬ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ (WebGPUë¡œ ëŒ€ì²´)
// import * as ort from 'onnxruntime-web'

// GPU ê°ì§€ ë° ì„¤ì •
export class GPUManager {
  private gpuAdapter: GPUAdapter | null = null
  private gpuDevice: GPUDevice | null = null
  private hasWebGPU: boolean = false

  async initialize(): Promise<boolean> {
    try {
      if (!('gpu' in navigator)) {
        console.warn('âŒ WebGPU not supported')
        return false
      }

      this.gpuAdapter = await navigator.gpu.requestAdapter({
        powerPreference: 'high-performance'
      })

      if (!this.gpuAdapter) {
        console.warn('âŒ No GPU adapter found')
        return false
      }

      this.gpuDevice = await this.gpuAdapter.requestDevice()
      this.hasWebGPU = true

      console.log('âœ… GPU initialized:', this.gpuAdapter)
      return true
    } catch (error) {
      console.error('GPU initialization failed:', error)
      return false
    }
  }

  isSupported(): boolean {
    return this.hasWebGPU
  }

  getDevice(): GPUDevice | null {
    return this.gpuDevice
  }

  async getInfo(): Promise<any> {
    if (!this.gpuAdapter) return null
    
    try {
      const info = await this.gpuAdapter.requestAdapterInfo()
      return {
        vendor: info.vendor || 'Unknown',
        device: info.device || info.description || 'Unknown GPU',
        architecture: info.architecture || 'Unknown'
      }
    } catch {
      return { device: 'WebGPU Available' }
    }
  }
}

// ONNX Runtime ì„¤ì •
export class ONNXManager {
  private session: ort.InferenceSession | null = null
  private modelLoaded: boolean = false

  async setupBackend(useWebGPU: boolean): Promise<void> {
    try {
      if (useWebGPU) {
        // WebGPU ë°±ì—”ë“œ ì‹œë„
        ort.env.wasm.numThreads = 4
        ort.env.wasm.simd = true
        ort.env.webgpu.powerPreference = 'high-performance'
        console.log('âœ… ONNX Runtime WebGPU backend configured')
      } else {
        // WASM ë°±ì—”ë“œ í´ë°±
        ort.env.wasm.numThreads = navigator.hardwareConcurrency || 4
        ort.env.wasm.simd = true
        console.log('âœ… ONNX Runtime WASM backend configured')
      }
    } catch (error) {
      console.error('ONNX backend setup failed:', error)
      throw error
    }
  }

  async loadModel(modelUrl: string, useWebGPU: boolean): Promise<void> {
    try {
      console.log(`ğŸ“¥ Loading model from ${modelUrl}...`)
      
      const executionProvider = useWebGPU ? 'webgpu' : 'wasm'
      
      this.session = await ort.InferenceSession.create(modelUrl, {
        executionProviders: [executionProvider],
        graphOptimizationLevel: 'all',
      })

      this.modelLoaded = true
      console.log('âœ… Model loaded successfully')
    } catch (error) {
      console.error('Model loading failed:', error)
      throw error
    }
  }

  async run(inputs: ort.InferenceSession.OnnxValueMapType): Promise<ort.InferenceSession.OnnxValueMapType> {
    if (!this.session) {
      throw new Error('Model not loaded')
    }
    return await this.session.run(inputs)
  }

  isLoaded(): boolean {
    return this.modelLoaded
  }
}

// ì´ë¯¸ì§€ ìƒì„± íŒŒì´í”„ë¼ì¸
export interface GenerationParams {
  prompt: string
  negativePrompt?: string
  width?: number
  height?: number
  steps?: number
  guidanceScale?: number
  seed?: number
}

export class ImageGenerator {
  private gpuManager: GPUManager
  private onnxManager: ONNXManager
  private initialized: boolean = false

  constructor() {
    this.gpuManager = new GPUManager()
    this.onnxManager = new ONNXManager()
  }

  async initialize(onProgress?: (message: string, percent: number) => void): Promise<void> {
    try {
      onProgress?.('GPU ì´ˆê¸°í™” ì¤‘...', 10)
      const hasGPU = await this.gpuManager.initialize()

      onProgress?.('ONNX Runtime ì„¤ì • ì¤‘...', 30)
      await this.onnxManager.setupBackend(hasGPU)

      onProgress?.('AI ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ', 100)
      this.initialized = true

      console.log('âœ… Image Generator initialized')
    } catch (error) {
      console.error('Initialization failed:', error)
      throw error
    }
  }

  async generate(params: GenerationParams, onProgress?: (stage: string, percent: number) => void): Promise<string> {
    if (!this.initialized) {
      throw new Error('Generator not initialized')
    }

    try {
      // í˜„ì¬ëŠ” Hugging Face Inference APIë¥¼ ì‚¬ìš© (ì™„ì „ ë¬´ë£Œ)
      // ë‚˜ì¤‘ì— ë¡œì»¬ ONNX ëª¨ë¸ë¡œ êµì²´ ì˜ˆì •
      return await this.generateViaAPI(params, onProgress)
    } catch (error) {
      console.error('Generation failed:', error)
      throw error
    }
  }

  private async generateViaAPI(params: GenerationParams, onProgress?: (stage: string, percent: number) => void): Promise<string> {
    onProgress?.('í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬ ì¤‘...', 20)
    
    // Stable Diffusion ë¬´ë£Œ API ì‚¬ìš©
    const API_URL = 'https://api-inference.huggingface.co/models/stabilityai/stable-diffusion-xl-base-1.0'
    
    onProgress?.('AI ì´ë¯¸ì§€ ìƒì„± ì¤‘...', 40)

    try {
      const response = await fetch(API_URL, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          inputs: params.prompt,
          parameters: {
            negative_prompt: params.negativePrompt || '',
            num_inference_steps: params.steps || 30,
            guidance_scale: params.guidanceScale || 7.5,
          }
        })
      })

      onProgress?.('ì´ë¯¸ì§€ í›„ì²˜ë¦¬ ì¤‘...', 80)

      if (!response.ok) {
        // API ì‚¬ìš© ë¶ˆê°€ ì‹œ Canvasë¡œ í´ë°±
        return this.generateFallback(params)
      }

      const blob = await response.blob()
      const imageUrl = URL.createObjectURL(blob)

      onProgress?.('ìƒì„± ì™„ë£Œ!', 100)
      return imageUrl
    } catch (error) {
      console.error('API generation failed, using fallback:', error)
      return this.generateFallback(params)
    }
  }

  private async generateFallback(params: GenerationParams): Promise<string> {
    // Canvasë¥¼ ì‚¬ìš©í•œ í´ë°± ì´ë¯¸ì§€ ìƒì„±
    return new Promise((resolve) => {
      const canvas = document.createElement('canvas')
      canvas.width = params.width || 512
      canvas.height = params.height || 512
      const ctx = canvas.getContext('2d')!

      // ê·¸ë¼ë°ì´ì…˜ ë°°ê²½
      const gradient = ctx.createLinearGradient(0, 0, canvas.width, canvas.height)
      
      // í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ìƒ‰ìƒ ì„ íƒ
      const colors = this.getColorsFromPrompt(params.prompt)
      gradient.addColorStop(0, colors[0])
      gradient.addColorStop(0.5, colors[1])
      gradient.addColorStop(1, colors[2])
      
      ctx.fillStyle = gradient
      ctx.fillRect(0, 0, canvas.width, canvas.height)

      // í…ìŠ¤íŠ¸ ì¶”ê°€
      ctx.fillStyle = 'white'
      ctx.font = 'bold 28px Arial'
      ctx.textAlign = 'center'
      ctx.shadowColor = 'rgba(0,0,0,0.5)'
      ctx.shadowBlur = 10
      
      ctx.fillText('ğŸ¨ AI Generated', canvas.width / 2, 80)
      
      ctx.font = '20px Arial'
      ctx.shadowBlur = 5
      
      // í”„ë¡¬í”„íŠ¸ë¥¼ ì—¬ëŸ¬ ì¤„ë¡œ í‘œì‹œ
      const words = params.prompt.split(' ')
      let line = ''
      let y = 150
      
      for (let word of words) {
        const testLine = line + word + ' '
        const metrics = ctx.measureText(testLine)
        
        if (metrics.width > canvas.width - 80 && line !== '') {
          ctx.fillText(line, canvas.width / 2, y)
          line = word + ' '
          y += 35
        } else {
          line = testLine
        }
      }
      ctx.fillText(line, canvas.width / 2, y)

      // ì¥ì‹ ìš”ì†Œ
      ctx.font = '16px Arial'
      ctx.fillStyle = 'rgba(255,255,255,0.7)'
      ctx.fillText('Demo Mode - Upgrade for AI Generation', canvas.width / 2, canvas.height - 40)

      resolve(canvas.toDataURL('image/png'))
    })
  }

  private getColorsFromPrompt(prompt: string): [string, string, string] {
    const lower = prompt.toLowerCase()
    
    // í‚¤ì›Œë“œ ê¸°ë°˜ ìƒ‰ìƒ ë§¤ì¹­
    if (lower.includes('sunset') || lower.includes('orange')) {
      return ['#FF6B6B', '#FF8E53', '#FEE140']
    } else if (lower.includes('ocean') || lower.includes('sea') || lower.includes('blue')) {
      return ['#667eea', '#4facfe', '#00f2fe']
    } else if (lower.includes('forest') || lower.includes('green') || lower.includes('nature')) {
      return ['#56ab2f', '#7cc576', '#a8e063']
    } else if (lower.includes('night') || lower.includes('dark') || lower.includes('space')) {
      return ['#0f2027', '#203a43', '#2c5364']
    } else if (lower.includes('pink') || lower.includes('flower')) {
      return ['#f093fb', '#f5576c', '#fa709a']
    } else {
      return ['#667eea', '#764ba2', '#f093fb']
    }
  }

  isInitialized(): boolean {
    return this.initialized
  }

  hasGPU(): boolean {
    return this.gpuManager.isSupported()
  }

  async getGPUInfo(): Promise<any> {
    return await this.gpuManager.getInfo()
  }
}

// IndexedDB ìºì‹± ì‹œìŠ¤í…œ
export class ModelCache {
  private dbName = 'ai-studio-models'
  private storeName = 'models'
  private db: IDBDatabase | null = null

  async initialize(): Promise<void> {
    return new Promise((resolve, reject) => {
      const request = indexedDB.open(this.dbName, 1)

      request.onerror = () => reject(request.error)
      request.onsuccess = () => {
        this.db = request.result
        resolve()
      }

      request.onupgradeneeded = (event) => {
        const db = (event.target as IDBOpenDBRequest).result
        if (!db.objectStoreNames.contains(this.storeName)) {
          db.createObjectStore(this.storeName)
        }
      }
    })
  }

  async cacheModel(key: string, data: ArrayBuffer): Promise<void> {
    if (!this.db) throw new Error('Database not initialized')

    return new Promise((resolve, reject) => {
      const transaction = this.db!.transaction([this.storeName], 'readwrite')
      const store = transaction.objectStore(this.storeName)
      const request = store.put(data, key)

      request.onsuccess = () => resolve()
      request.onerror = () => reject(request.error)
    })
  }

  async getModel(key: string): Promise<ArrayBuffer | null> {
    if (!this.db) throw new Error('Database not initialized')

    return new Promise((resolve, reject) => {
      const transaction = this.db!.transaction([this.storeName], 'readonly')
      const store = transaction.objectStore(this.storeName)
      const request = store.get(key)

      request.onsuccess = () => resolve(request.result || null)
      request.onerror = () => reject(request.error)
    })
  }

  async hasModel(key: string): Promise<boolean> {
    const model = await this.getModel(key)
    return model !== null
  }
}

// ì „ì—­ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
let globalImageGenerator: ImageGenerator | null = null

export function getImageGenerator(): ImageGenerator {
  if (!globalImageGenerator) {
    globalImageGenerator = new ImageGenerator()
  }
  return globalImageGenerator
}

export default {
  GPUManager,
  ONNXManager,
  ImageGenerator,
  ModelCache,
  getImageGenerator
}
