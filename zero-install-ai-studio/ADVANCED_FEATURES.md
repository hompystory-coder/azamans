# ðŸš€ ê³ ê¸‰ ê¸°ëŠ¥ ê°€ì´ë“œ

**ìž‘ì„±ì¼**: 2024-12-27  
**ë²„ì „**: v3.0.0  
**ìƒíƒœ**: êµ¬í˜„ ê°€ì´ë“œ

---

## ðŸ“‹ ëª©ì°¨
1. [ìž¥ë¥´ë³„ ìŠ¤í† ë¦¬ êµ¬ì¡° ìžë™ ì ìš©](#ìž¥ë¥´ë³„-ìŠ¤í† ë¦¬-êµ¬ì¡°-ìžë™-ì ìš©)
2. [ë‹¤êµ­ì–´ ì‡¼ì¸  ìƒì„±](#ë‹¤êµ­ì–´-ì‡¼ì¸ -ìƒì„±)
3. [GPU ì„œë²„ ë Œíƒˆ ê°€ì´ë“œ](#gpu-ì„œë²„-ë Œíƒˆ-ê°€ì´ë“œ)

---

## 1ï¸âƒ£ ìž¥ë¥´ë³„ ìŠ¤í† ë¦¬ êµ¬ì¡° ìžë™ ì ìš©

### ê°œë…

í˜„ìž¬ ì‹œìŠ¤í…œì€ ëª¨ë“  ìŠ¤í† ë¦¬ì— ë™ì¼í•œ 5ë§‰ êµ¬ì¡°ë¥¼ ì ìš©í•©ë‹ˆë‹¤.  
**ê°œì„ **: ìž¥ë¥´ ìžë™ ì¸ì‹ â†’ ë§žì¶¤ êµ¬ì¡° ì ìš©

### ì§€ì› ìž¥ë¥´

| ìž¥ë¥´ | êµ¬ì¡° | íŠ¹ì§• |
|------|------|------|
| **ë™í™”** | 5ë§‰ | êµí›ˆ, í•´í”¼ì—”ë”©, ë§ˆë²• ìš”ì†Œ |
| **ì•¡ì…˜** | 3ë§‰ | ë¹ ë¥¸ ì „ê°œ, í´ë¼ì´ë§¥ìŠ¤ ì¤‘ì‹¬ |
| **ë¡œë§¨ìŠ¤** | 5ë§‰ | ê°ì • ì¤‘ì‹¬, ê°ˆë“± í•´ì†Œ |
| **ê³µí¬** | 4ë§‰ | ê¸´ìž¥ê° ëˆ„ì , ë°˜ì „ ì—”ë”© |
| **ì½”ë¯¸ë””** | 3ë§‰ | ê°€ë²¼ìš´ ê°ˆë“±, í•´ê²° |
| **SF** | ì˜ì›…ì˜ ì—¬ì • | 12ë‹¨ê³„ êµ¬ì¡° |

### êµ¬í˜„ ë°©ë²•

```python
# genre_detector.py
import requests

def detect_genre_with_ollama(user_input: str, model: str = "llama3.1:8b") -> dict:
    """
    Ollamaë¡œ ìž¥ë¥´ ìžë™ ì¸ì‹
    
    Returns:
        {
            "genre": "ë™í™”",
            "structure": "5ë§‰",
            "tone": "ë”°ëœ»í•œ",
            "keywords": ["ë§ˆë²•", "êµí›ˆ", "í•´í”¼ì—”ë”©"]
        }
    """
    prompt = f"""ë‹¤ìŒ ìŠ¤í† ë¦¬ì˜ ìž¥ë¥´ë¥¼ íŒë‹¨í•˜ì„¸ìš”:
"{user_input}"

ìž¥ë¥´ ì˜µì…˜: ë™í™”, ì•¡ì…˜, ë¡œë§¨ìŠ¤, ê³µí¬, ì½”ë¯¸ë””, SF
êµ¬ì¡° ì˜µì…˜: 3ë§‰, 4ë§‰, 5ë§‰, ì˜ì›…ì˜ ì—¬ì •

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{{"genre": "ë™í™”", "structure": "5ë§‰", "tone": "ë”°ëœ»í•œ", "keywords": ["ë§ˆë²•", "êµí›ˆ"]}}

JSONë§Œ ì¶œë ¥:"""
    
    response = requests.post(
        "http://localhost:11434/api/generate",
        json={"model": model, "prompt": prompt, "stream": False}
    )
    
    if response.status_code == 200:
        result = response.json()["response"]
        # JSON íŒŒì‹±
        import json
        return json.loads(result)
    
    return {"genre": "ì¼ë°˜", "structure": "5ë§‰", "tone": "ì¤‘ë¦½ì "}


# ìž¥ë¥´ë³„ êµ¬ì¡° ì ìš©
GENRE_STRUCTURES = {
    "ë™í™”": {
        "acts": 5,
        "act_names": ["ë°œë‹¨", "ì „ê°œ", "ìœ„ê¸°", "ì ˆì •", "ê²°ë§"],
        "narration_style": "curious",
        "mood_palette": ["ë”°ëœ»í•œ", "ì‹ ë¹„ë¡œìš´", "í¬ë§ì°¬"]
    },
    "ì•¡ì…˜": {
        "acts": 3,
        "act_names": ["ë„ìž…", "ê°ˆë“±", "í•´ê²°"],
        "narration_style": "dramatic",
        "mood_palette": ["ê¸´ë°•í•œ", "í­ë°œì ì¸", "ì¹´íƒ€ë¥´ì‹œìŠ¤"]
    },
    "ë¡œë§¨ìŠ¤": {
        "acts": 5,
        "act_names": ["ë§Œë‚¨", "ì ‘ê·¼", "ê°ˆë“±", "í™”í•´", "ê²°í•©"],
        "narration_style": "calm",
        "mood_palette": ["ì„¤ë ˆëŠ”", "ì•„í”ˆ", "ê°ë™ì ì¸"]
    },
    "ê³µí¬": {
        "acts": 4,
        "act_names": ["í‰ì˜¨", "ë¶ˆì•ˆ", "ê³µí¬", "ë°˜ì „"],
        "narration_style": "dramatic",
        "mood_palette": ["ë¶ˆì•ˆí•œ", "ì„¬ëœ©í•œ", "ì¶©ê²©ì ì¸"]
    }
}


def apply_genre_structure(user_input: str, scenes_count: int) -> dict:
    """
    ìž¥ë¥´ ê°ì§€ í›„ ë§žì¶¤ êµ¬ì¡° ì ìš©
    """
    # 1. ìž¥ë¥´ ê°ì§€
    genre_info = detect_genre_with_ollama(user_input)
    genre = genre_info["genre"]
    
    # 2. í•´ë‹¹ ìž¥ë¥´ êµ¬ì¡° ë¡œë“œ
    structure = GENRE_STRUCTURES.get(genre, GENRE_STRUCTURES["ë™í™”"])
    
    # 3. ì”¬ ë°°ë¶„
    acts_count = structure["acts"]
    scenes_per_act = scenes_count // acts_count
    
    # 4. ì”¬ ìƒì„±
    scenes = []
    for act_num in range(acts_count):
        for scene_in_act in range(scenes_per_act):
            scene = {
                "act_name": structure["act_names"][act_num],
                "mood": structure["mood_palette"][act_num % len(structure["mood_palette"])],
                "style": structure["narration_style"]
            }
            scenes.append(scene)
    
    return {
        "genre": genre,
        "structure": structure,
        "scenes": scenes
    }
```

### ì‚¬ìš© ì˜ˆì‹œ

```python
# story_generator.pyì— í†µí•©
from genre_detector import apply_genre_structure

def generate_story_with_genre_detection(user_input: str, duration: int = 30):
    scenes_count = max(5, duration // 4)
    
    # ìž¥ë¥´ ê°ì§€ ë° êµ¬ì¡° ì ìš©
    genre_result = apply_genre_structure(user_input, scenes_count)
    
    logger.info(f"ðŸŽ­ ìž¥ë¥´ ê°ì§€: {genre_result['genre']}")
    logger.info(f"ðŸ“ êµ¬ì¡°: {genre_result['structure']['acts']}ë§‰")
    
    # ìž¥ë¥´ë³„ ë§žì¶¤ ìŠ¤í† ë¦¬ ìƒì„±
    # ...
```

---

## 2ï¸âƒ£ ë‹¤êµ­ì–´ ì‡¼ì¸  ìƒì„±

### ì§€ì› ì–¸ì–´

| ì–¸ì–´ | Ollama ë²ˆì—­ | TTS ì§€ì› | í’ˆì§ˆ |
|------|------------|---------|------|
| ðŸ‡°ðŸ‡· í•œêµ­ì–´ | ì›ë³¸ | âœ… | â­â­â­â­â­ |
| ðŸ‡ºðŸ‡¸ ì˜ì–´ | âœ… | âœ… | â­â­â­â­â­ |
| ðŸ‡¯ðŸ‡µ ì¼ë³¸ì–´ | âœ… | âœ… | â­â­â­â­ |
| ðŸ‡¨ðŸ‡³ ì¤‘êµ­ì–´ | âœ… | âœ… | â­â­â­â­ |
| ðŸ‡ªðŸ‡¸ ìŠ¤íŽ˜ì¸ì–´ | âœ… | âœ… | â­â­â­ |

### êµ¬í˜„ ë°©ë²•

```python
# multilang_translator.py
import requests

class MultiLangTranslator:
    """Ollama ê¸°ë°˜ ë‹¤êµ­ì–´ ë²ˆì—­ê¸°"""
    
    LANGUAGES = {
        "ko": "í•œêµ­ì–´",
        "en": "English",
        "ja": "æ—¥æœ¬èªž",
        "zh": "ä¸­æ–‡",
        "es": "EspaÃ±ol"
    }
    
    def __init__(self, model: str = "llama3.1:8b"):
        self.model = model
        self.base_url = "http://localhost:11434"
    
    def translate_narration(
        self, 
        korean_text: str, 
        target_lang: str = "en"
    ) -> str:
        """
        ë‚˜ë ˆì´ì…˜ì„ ëª©í‘œ ì–¸ì–´ë¡œ ë²ˆì—­
        
        Args:
            korean_text: í•œêµ­ì–´ ë‚˜ë ˆì´ì…˜
            target_lang: ëª©í‘œ ì–¸ì–´ ì½”ë“œ (en, ja, zh, es)
            
        Returns:
            ë²ˆì—­ëœ í…ìŠ¤íŠ¸
        """
        lang_name = self.LANGUAGES.get(target_lang, "English")
        
        prompt = f"""ë‹¤ìŒ í•œêµ­ì–´ ë‚˜ë ˆì´ì…˜ì„ {lang_name}ë¡œ ë²ˆì—­í•˜ì„¸ìš”.

ì›ë¬¸: "{korean_text}"

ìš”êµ¬ì‚¬í•­:
1. ê°™ì€ í†¤ê³¼ ëŠë‚Œ ìœ ì§€
2. 30ìž ì´ë‚´ (ì›ë¬¸ ê¸¸ì´ ìœ ì§€)
3. ìžì—°ìŠ¤ëŸ¬ìš´ êµ¬ì–´ì²´
4. ë²ˆì—­ë¬¸ë§Œ ì¶œë ¥ (ì„¤ëª… ì—†ì´)

{lang_name} ë²ˆì—­:"""
        
        response = requests.post(
            f"{self.base_url}/api/generate",
            json={
                "model": self.model,
                "prompt": prompt,
                "stream": False,
                "options": {"temperature": 0.3}
            }
        )
        
        if response.status_code == 200:
            translated = response.json()["response"].strip()
            return translated
        
        return korean_text  # í´ë°±: ì›ë¬¸ ë°˜í™˜
    
    def translate_story_batch(
        self, 
        scenes: list[dict], 
        target_lang: str = "en"
    ) -> list[dict]:
        """
        ì „ì²´ ìŠ¤í† ë¦¬ì˜ ë‚˜ë ˆì´ì…˜ì„ ì¼ê´„ ë²ˆì—­
        
        Args:
            scenes: ì”¬ ë¦¬ìŠ¤íŠ¸ (ê° ì”¬ì— "narration" í¬í•¨)
            target_lang: ëª©í‘œ ì–¸ì–´
            
        Returns:
            ë²ˆì—­ëœ ì”¬ ë¦¬ìŠ¤íŠ¸
        """
        translated_scenes = []
        
        for scene in scenes:
            translated_scene = scene.copy()
            
            # ë‚˜ë ˆì´ì…˜ ë²ˆì—­
            translated_scene["narration"] = self.translate_narration(
                scene["narration"],
                target_lang
            )
            
            # ì œëª© ë²ˆì—­
            translated_scene["title"] = self.translate_narration(
                scene["title"],
                target_lang
            )
            
            translated_scenes.append(translated_scene)
        
        return translated_scenes


# ì‚¬ìš© ì˜ˆì‹œ
translator = MultiLangTranslator()

# í•œêµ­ì–´ ìŠ¤í† ë¦¬ ìƒì„±
korean_story = generate_story_script("ìš°ì£¼ ë¹„í–‰ì‚¬ì˜ ëª¨í—˜", duration=30)

# ì˜ì–´ë¡œ ë²ˆì—­
english_story = translator.translate_story_batch(
    korean_story["scenes"], 
    target_lang="en"
)

# ì¼ë³¸ì–´ë¡œ ë²ˆì—­
japanese_story = translator.translate_story_batch(
    korean_story["scenes"], 
    target_lang="ja"
)
```

### TTS ì—°ë™

```python
# Google TTS (ë‹¤êµ­ì–´ ì§€ì›)
from gtts import gTTS

def generate_multilang_tts(text: str, lang: str = "ko"):
    """
    ë‹¤êµ­ì–´ TTS ìƒì„±
    
    Args:
        text: í…ìŠ¤íŠ¸
        lang: ì–¸ì–´ ì½”ë“œ (ko, en, ja, zh-CN, es)
    """
    tts = gTTS(text=text, lang=lang)
    tts.save(f"narration_{lang}.mp3")
```

---

## 3ï¸âƒ£ GPU ì„œë²„ ë Œíƒˆ ê°€ì´ë“œ

### ì„œë¹„ìŠ¤ ë¹„êµ

| ì„œë¹„ìŠ¤ | GPU | ì‹œê°„ë‹¹ ë¹„ìš© | ì›” ë¹„ìš© (24/7) | ì¶”ì²œë„ |
|--------|-----|------------|----------------|--------|
| **Vast.ai** | RTX 3060 (12GB) | $0.15 | $108 | â­â­â­â­â­ |
| **RunPod** | RTX 3090 (24GB) | $0.20 | $144 | â­â­â­â­ |
| **Lambda Labs** | A100 (40GB) | $0.50 | $360 | â­â­â­ |
| **AWS EC2** | g4dn.xlarge | $0.526 | $379 | â­â­ |

### Vast.ai ì„¤ì • ê°€ì´ë“œ (ìµœì €ê°€)

#### Step 1: ê³„ì • ìƒì„±
```
1. https://vast.ai/ ì ‘ì†
2. Sign Up (ì´ë©”ì¼ ê°€ìž…)
3. $10 ì¶©ì „ (ì´ˆê¸° í…ŒìŠ¤íŠ¸ìš©)
```

#### Step 2: GPU ì¸ìŠ¤í„´ìŠ¤ ê²€ìƒ‰
```
Filter:
- GPU: RTX 3060 ì´ìƒ
- VRAM: 12GB ì´ìƒ
- Disk: 50GB ì´ìƒ
- Upload: 100 Mbps ì´ìƒ

Sort: Price (lowest first)

ì˜ˆìƒ ê°€ê²©: $0.10-0.20/hr
```

#### Step 3: SSH ì ‘ì† ì„¤ì •
```bash
# Vast.aiì—ì„œ SSH í¬íŠ¸ í™•ì¸ (ì˜ˆ: ssh://root@123.456.78.90:12345)
ssh -p 12345 root@123.456.78.90

# ë¹„ë°€ë²ˆí˜¸ëŠ” ëŒ€ì‹œë³´ë“œì— í‘œì‹œ
```

#### Step 4: ComfyUI ì„¤ì¹˜
```bash
# 1. ì—…ë°ì´íŠ¸
apt update && apt upgrade -y

# 2. Python í™˜ê²½
apt install -y python3-pip python3-venv git

# 3. ComfyUI í´ë¡ 
cd /root
git clone https://github.com/comfyanonymous/ComfyUI.git
cd ComfyUI

# 4. ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt

# 5. SDXL ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
cd models/checkpoints
wget https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0.safetensors

# 6. ì‹¤í–‰
cd /root/ComfyUI
python main.py --listen 0.0.0.0 --port 8188

# 7. í¬íŠ¸ í¬ì›Œë”© (Vast.ai ëŒ€ì‹œë³´ë“œì—ì„œ 8188 í¬íŠ¸ ì—´ê¸°)
# ë¸Œë¼ìš°ì €: http://[YOUR_INSTANCE_IP]:8188
```

#### Step 5: ìžë™ ì‹œìž‘ ì„¤ì •
```bash
# systemd ì„œë¹„ìŠ¤ ìƒì„±
cat > /etc/systemd/system/comfyui.service << 'EOF'
[Unit]
Description=ComfyUI
After=network.target

[Service]
Type=simple
User=root
WorkingDirectory=/root/ComfyUI
ExecStart=/usr/bin/python3 main.py --listen 0.0.0.0 --port 8188
Restart=always

[Install]
WantedBy=multi-user.target
EOF

# ì„œë¹„ìŠ¤ í™œì„±í™”
systemctl enable comfyui
systemctl start comfyui
systemctl status comfyui
```

### RunPod ì„¤ì • ê°€ì´ë“œ (ê³ ì„±ëŠ¥)

#### Step 1: ê³„ì • ìƒì„±
```
1. https://runpod.io/ ì ‘ì†
2. Sign Up
3. $25 ì¶©ì „
```

#### Step 2: Pod ìƒì„±
```
Template: RunPod PyTorch
GPU: RTX 3090 (24GB)
Disk: 100GB

ì˜ˆìƒ ê°€ê²©: $0.20/hr
```

#### Step 3: Jupyter ë˜ëŠ” SSH ì ‘ì†
```
RunPodëŠ” Jupyter Notebook ì œê³µ
ë˜ëŠ” SSHë¡œ ì§ì ‘ ì ‘ì† ê°€ëŠ¥
```

#### Step 4: ComfyUI ì„¤ì¹˜ (ë™ì¼)
```bash
# Vast.aiì™€ ë™ì¼í•œ ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš©
```

### ë¹„ìš© ìµœì í™” íŒ

1. **On-Demand vs ê³„ì•½í˜•**
   - On-Demand: ì‹œê°„ë‹¹ ê³¼ê¸ˆ, ìœ ì—°í•¨
   - ê³„ì•½í˜• (Reserved): ì›” ë‹¨ìœ„, 30-50% ì €ë ´

2. **Spot ì¸ìŠ¤í„´ìŠ¤ í™œìš©**
   - Vast.ai/RunPodì˜ Spot ì¸ìŠ¤í„´ìŠ¤
   - 50-70% í• ì¸ (ì¤‘ë‹¨ ìœ„í—˜ ìžˆìŒ)
   - ê°œë°œ/í…ŒìŠ¤íŠ¸ìš© ìµœì 

3. **ì‚¬ìš© íŒ¨í„´ ìµœì í™”**
   - ì•¼ê°„/ì£¼ë§ë§Œ ì‚¬ìš©: ì›” $30-50
   - 24/7 ìš´ì˜: ì›” $100-150
   - ë°°ì¹˜ ìž‘ì—… (1ì‹œê°„ ì§‘ì¤‘): ì›” $10-20

---

## ðŸŽ¯ ìµœì¢… êµ¬í˜„ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ì´ë¯¸ì§€/ì˜ìƒ ìƒì„±
- [x] Replicate API ì—°ë™
- [x] Hugging Face API ì—°ë™
- [ ] ë¡œì»¬ ComfyUI ì„¤ì¹˜ (GPU ì„œë²„)

### ë‚˜ë ˆì´ì…˜ ìƒì„±
- [x] 75ê°œ ê³ ì • ë‚˜ë ˆì´ì…˜ í’€
- [x] Ollama ìžë™ ìƒì„± ì‹œìŠ¤í…œ
- [ ] ìž¥ë¥´ë³„ ë§žì¶¤ ë‚˜ë ˆì´ì…˜

### ìŠ¤í† ë¦¬ êµ¬ì¡°
- [x] 5ë§‰ êµ¬ì¡° (ê¸°ë³¸)
- [ ] ìž¥ë¥´ ìžë™ ê°ì§€
- [ ] ìž¥ë¥´ë³„ ë§žì¶¤ êµ¬ì¡°

### ë‹¤êµ­ì–´ ì§€ì›
- [x] í•œêµ­ì–´ (ê¸°ë³¸)
- [ ] Ollama ë²ˆì—­ ì‹œìŠ¤í…œ
- [ ] ë‹¤êµ­ì–´ TTS ì—°ë™

### ì„œë²„ ì¸í”„ë¼
- [ ] GPU ì„œë²„ ë Œíƒˆ (Vast.ai/RunPod)
- [ ] ComfyUI ì„¤ì¹˜ ë° ì„¤ì •
- [ ] API ì—”ë“œí¬ì¸íŠ¸ ì—°ë™

---

## ðŸ“ž ê´€ë ¨ ë¬¸ì„œ

- [FREE_IMAGE_VIDEO_AI.md](./FREE_IMAGE_VIDEO_AI.md) - ë¬´ë£Œ ì´ë¯¸ì§€/ì˜ìƒ AI ê°€ì´ë“œ
- [SERVER_AI_CAPABILITIES.md](./SERVER_AI_CAPABILITIES.md) - ì„œë²„ AI ê¸°ëŠ¥ ë¶„ì„
- [OLLAMA_INTEGRATION.md](./OLLAMA_INTEGRATION.md) - Ollama í†µí•© ê°€ì´ë“œ

---

**Â© 2024 Zero-Install AI Studio. All rights reserved.**
